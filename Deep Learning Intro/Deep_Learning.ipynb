{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c83c6ff",
      "metadata": {
        "id": "1c83c6ff"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60614178",
      "metadata": {
        "id": "60614178"
      },
      "source": [
        "### Import necessary libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a326e8b",
      "metadata": {
        "scrolled": true,
        "id": "6a326e8b"
      },
      "outputs": [],
      "source": [
        "#from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "76b644b2",
      "metadata": {
        "id": "76b644b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "X, y = make_regression(n_samples=500, n_features=10,\n",
        "                       noise=1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da8256c",
      "metadata": {
        "id": "6da8256c"
      },
      "source": [
        "We first import the necessary libraries such as `Scikit-learn`, `Numpy` and `Matplotlib.` We also generated a synthetic dataset from the Scikit-learn dataset library, which is a regression dataset with 500 instances and 10 attributes. We then separate the independent variable X and dependent variable y from the dataset.\n",
        "\n",
        "Carry out any preprocessing on the dataset\n",
        "\n",
        "Before proceeding with any regression algorithm, it is always recommended to perform preprocessing steps such as feature scaling, imputation, etc. Here, we will apply StandardScaler to standardize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2e4ce1bd",
      "metadata": {
        "id": "2e4ce1bd"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b54f95f",
      "metadata": {
        "id": "6b54f95f"
      },
      "source": [
        "Split the dataset into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a43f81c6",
      "metadata": {
        "id": "a43f81c6"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb834114",
      "metadata": {
        "id": "bb834114"
      },
      "source": [
        "In this step, we split the dataset into training and testing sets. We keep `70%` of the dataset for training and `30%` for testing. We also set a random seed for reproducibility."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e3a6cde",
      "metadata": {
        "id": "5e3a6cde"
      },
      "source": [
        "### Implement a Linear Regression Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "63a228b2",
      "metadata": {
        "id": "63a228b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "LinearR = LinearRegression()\n",
        "LinearR.fit(X_train, y_train)\n",
        "y_pred = LinearR.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3bb8c2",
      "metadata": {
        "id": "cb3bb8c2"
      },
      "source": [
        "Here, we import the Perceptron algorithm from Scikit-learn's linear_model library. We then instantiate the perceptron object and fit it to our training data. We use the trained model to predict the target variable on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56bef5d",
      "metadata": {
        "id": "a56bef5d"
      },
      "source": [
        "### Evaluate the performance of the regression problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "010e627f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "010e627f",
        "outputId": "f0c81acd-a896-4df0-decb-3d33b7b0ad4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error:  0.9052902177417578\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean Squared Error: \", mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f0d078",
      "metadata": {
        "id": "b1f0d078"
      },
      "source": [
        "In this step, we calculate the mean squared error between the predicted values and actual values. This will give us an idea of how well our model is performing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a6ac84",
      "metadata": {
        "id": "c0a6ac84"
      },
      "source": [
        "### Plot the residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "20183fa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "20183fa4",
        "outputId": "a10c34c9-575e-455f-ef32-a9e4fee34e3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "residuals = y_test - y_pred\n",
        "plt.scatter(y_pred, residuals)\n",
        "plt.title('Residual Plot')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1722819a",
      "metadata": {
        "id": "1722819a"
      },
      "source": [
        "Finally, we plot the residual between the predicted and actual values to visualize the errors in our model. A good model will have residuals randomly scattered around zero.\n",
        "\n",
        "Overall, this code implements a perceptron algorithm for the Boston dataset, evaluates its performance using mean squared error and plots the residual to visualize the errors. Other regression algorithms such as decision tree regression or random forest regression can also be used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4cbf17f",
      "metadata": {
        "id": "d4cbf17f"
      },
      "source": [
        "# Neural Network (Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "599a2e1c",
      "metadata": {
        "id": "599a2e1c"
      },
      "outputs": [],
      "source": [
        "#from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e32bc8",
      "metadata": {
        "id": "38e32bc8"
      },
      "source": [
        "Data Preprocessing - apply StandardScaler to standardize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a360f887",
      "metadata": {
        "id": "a360f887"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09faf6f1",
      "metadata": {
        "id": "09faf6f1"
      },
      "source": [
        "### Split the dataset into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3d446d57",
      "metadata": {
        "id": "3d446d57"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "544e9d08",
      "metadata": {
        "id": "544e9d08"
      },
      "source": [
        "In this step, we split the dataset into training and testing sets. We keep 70% of the dataset for training and 30% for testing. We also set a random seed for reproducibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a2030c6",
      "metadata": {
        "id": "3a2030c6"
      },
      "source": [
        "### Implement a neural network model with 2 hidden layers using Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "72ced5c8",
      "metadata": {
        "id": "72ced5c8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    validation_data=(X_test, y_test), epochs=100,\n",
        "                    batch_size=32, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5c6514e",
      "metadata": {
        "id": "f5c6514e"
      },
      "source": [
        "Here, define a sequential neural network model using Keras. We add 2 dense layers with 64 neurons each and use the rectified linear unit (ReLU) activation function. We also add a final dense layer with a single neuron for output. We compile the model using the Adam optimizer and mean squared error (MSE) loss function.\n",
        "\n",
        "We then fit the model on the training data for 100 epochs with a batch size of 32. We also evaluate the model on the testing data using the validation_data parameter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec06b08",
      "metadata": {
        "id": "bec06b08"
      },
      "source": [
        "### Evaluate the performance of the regression problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cc058394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cc058394",
        "outputId": "f2ed0596-a6ac-4083-8781-4ead320fa605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Squared Error:  41.02366256713867\n",
            "Testing Mean Squared Error:  64.74259185791016\n"
          ]
        }
      ],
      "source": [
        "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Training Mean Squared Error: \", mse_train)\n",
        "print(\"Testing Mean Squared Error: \", mse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e2576b8",
      "metadata": {
        "id": "5e2576b8"
      },
      "source": [
        "In this step, we calculate the mean squared error between the predicted values and actual values for both training and testing sets. This will give us an idea of how well our model is performing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "165459b0",
      "metadata": {
        "id": "165459b0"
      },
      "source": [
        "2) Implement a neural network model with 2 hidden layers using Keras (activation function: Leaky ReLU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "27b8f6bd",
      "metadata": {
        "id": "27b8f6bd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import the LeakyReLU module and create a LeakyReLU instance\n",
        "from keras.layers import LeakyReLU\n",
        "leaky_relu = LeakyReLU(alpha=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fcb0250e",
      "metadata": {
        "id": "fcb0250e"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='leaky_relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(64, activation='leaky_relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    validation_data=(X_test, y_test), epochs=100,\n",
        "                    batch_size=32, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b7403fd",
      "metadata": {
        "id": "5b7403fd"
      },
      "source": [
        "Here, I define a sequential neural network model with 2 hidden layers as opposed to the previous model. The hidden layers consist of 64 neurons each and each of the layers uses the Leaky rectified linear unit (Leaky ReLU) activation function. There is also a final dense layer with a single neuron for output. The model is compiled using the Adam optimizer and mean squared error (MSE) loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the performance of the regression problem"
      ],
      "metadata": {
        "id": "2QtyiKpEZoNJ"
      },
      "id": "2QtyiKpEZoNJ"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "150e11d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "150e11d7",
        "outputId": "5ae1e26b-a533-4f6f-d778-3b4e89462c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Squared Error:  20.62482452392578\n",
            "Testing Mean Squared Error:  37.77157974243164\n"
          ]
        }
      ],
      "source": [
        "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Training Mean Squared Error: \", mse_train)\n",
        "print(\"Testing Mean Squared Error: \", mse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance experienced a slight reduction after decreasing the number of hidden layers and switching to the LeakyReLU activation function. This outcome is somewhat unexpected as the LeakyReLU function is typically anticipated to outperform the regular ReLU function employed in the previous model. Nevertheless, considering that the reduction in performance coincided with the reduction in the number of hidden layers, it is reasonable to attribute this outcome to the decrease in the model's complexity.\n",
        "\n",
        "The next implementation uses the same activation function (LeakyReLU) but adds an additional hidden layer. We shall observe if the LeakyReLU's performance increases with an increase in the number of hidden layers."
      ],
      "metadata": {
        "id": "fMdnytIEZl_6"
      },
      "id": "fMdnytIEZl_6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Implement a neural network model with 3 hidden layers using Keras (activation function: Leaky ReLU)"
      ],
      "metadata": {
        "id": "ErWiedyTZ86n"
      },
      "id": "ErWiedyTZ86n"
    },
    {
      "cell_type": "code",
      "source": [
        "leaky_relu = LeakyReLU(alpha=0.02)"
      ],
      "metadata": {
        "id": "fx_iB_2kZ6Hp"
      },
      "id": "fx_iB_2kZ6Hp",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation='leaky_relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(64, activation='leaky_relu'))\n",
        "model.add(Dense(32, activation='leaky_relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    validation_data=(X_test, y_test), epochs=100,\n",
        "                    batch_size=32, verbose=0)"
      ],
      "metadata": {
        "id": "axD5Mko2Z6Zv"
      },
      "id": "axD5Mko2Z6Zv",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, I create a sequential neural network model with 3 hidden layers, which differs from the previous model. The hidden layers are composed of 128, 64, and 32 neurons, respectively, and each of them utilizes the Leaky rectified linear unit (Leaky ReLU) activation function. Additionally, there is a final dense layer with a single neuron responsible for the output. To prepare the model for training, I compile it using the Adam optimizer and apply the mean squared error (MSE) loss function."
      ],
      "metadata": {
        "id": "ByhRJC5pamBp"
      },
      "id": "ByhRJC5pamBp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the performance of the regression problem"
      ],
      "metadata": {
        "id": "FDtrVIBHaphp"
      },
      "id": "FDtrVIBHaphp"
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "mse_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Training Mean Squared Error: \", mse_train)\n",
        "print(\"Testing Mean Squared Error: \", mse_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bOdEn1WAas7Y",
        "outputId": "015e338b-2b7b-4437-d6fa-7e4e672f53f8"
      },
      "id": "bOdEn1WAas7Y",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Squared Error:  3.8120782375335693\n",
            "Testing Mean Squared Error:  10.762750625610352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results above confirm the fact that the more hidden layers, the better the performance of the model. We can see that the testing MSE shows a drastic reduction from 42.68 to 11.264, after the addition of just one hidden layer consisting of 32 neurons."
      ],
      "metadata": {
        "id": "o01d-t-OazGI"
      },
      "id": "o01d-t-OazGI"
    },
    {
      "cell_type": "markdown",
      "id": "eb138f2f",
      "metadata": {
        "id": "eb138f2f"
      },
      "source": [
        "# Classification Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0922426f",
      "metadata": {
        "id": "0922426f"
      },
      "source": [
        "### Import necessary libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bbaf1740",
      "metadata": {
        "id": "bbaf1740"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4fac8a25",
      "metadata": {
        "id": "4fac8a25"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90d9352",
      "metadata": {
        "id": "b90d9352"
      },
      "source": [
        "In this step, we first import the necessary libraries such as Scikit-learn, Keras, Numpy and Matplotlib. We also load the Iris dataset from the Scikit-learn dataset library, which is a classification dataset with 150 instances and 4 attributes. We then separate the independent variable X and dependent variable y from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28d2b26",
      "metadata": {
        "id": "c28d2b26"
      },
      "source": [
        "### Data Preprocessing - apply StandardScaler to standardize the data and convert the target variable to categorical format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c48d8ee4",
      "metadata": {
        "id": "c48d8ee4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "acf7c137",
      "metadata": {
        "id": "acf7c137"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18b92650",
      "metadata": {
        "id": "18b92650"
      },
      "source": [
        "### Split the dataset into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "da7bf04f",
      "metadata": {
        "id": "da7bf04f"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2547e379",
      "metadata": {
        "id": "2547e379"
      },
      "source": [
        "In this step, we split the dataset into training and testing sets. We keep 70% of the dataset for training and 30% for testing. We also set a random seed for reproducibility.\n",
        "\n",
        "### Implement a neural network model with 3 hidden layers using Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "12153680",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "12153680",
        "outputId": "7b1a7c42-1e03-42f5-9f1f-ebd70f530809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 [==============================] - 1s 77ms/step - loss: 1.0711 - accuracy: 0.3524 - val_loss: 1.0422 - val_accuracy: 0.2889\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9960 - accuracy: 0.3524 - val_loss: 0.9730 - val_accuracy: 0.2889\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9382 - accuracy: 0.3524 - val_loss: 0.9206 - val_accuracy: 0.3111\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8900 - accuracy: 0.4476 - val_loss: 0.8725 - val_accuracy: 0.5333\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8444 - accuracy: 0.6857 - val_loss: 0.8259 - val_accuracy: 0.8222\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8021 - accuracy: 0.8000 - val_loss: 0.7811 - val_accuracy: 0.8444\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7585 - accuracy: 0.8190 - val_loss: 0.7366 - val_accuracy: 0.8444\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7159 - accuracy: 0.8286 - val_loss: 0.6919 - val_accuracy: 0.8444\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6725 - accuracy: 0.8286 - val_loss: 0.6477 - val_accuracy: 0.8444\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6296 - accuracy: 0.8381 - val_loss: 0.6048 - val_accuracy: 0.8444\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5891 - accuracy: 0.8476 - val_loss: 0.5636 - val_accuracy: 0.8444\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5502 - accuracy: 0.8476 - val_loss: 0.5250 - val_accuracy: 0.8667\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5157 - accuracy: 0.8762 - val_loss: 0.4873 - val_accuracy: 0.8667\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4811 - accuracy: 0.8762 - val_loss: 0.4530 - val_accuracy: 0.8667\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4500 - accuracy: 0.8667 - val_loss: 0.4218 - val_accuracy: 0.8667\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4223 - accuracy: 0.8667 - val_loss: 0.3926 - val_accuracy: 0.8222\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3957 - accuracy: 0.8762 - val_loss: 0.3668 - val_accuracy: 0.8667\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3714 - accuracy: 0.8762 - val_loss: 0.3447 - val_accuracy: 0.8667\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3504 - accuracy: 0.8762 - val_loss: 0.3240 - val_accuracy: 0.8667\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3314 - accuracy: 0.8667 - val_loss: 0.3068 - val_accuracy: 0.8667\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3169 - accuracy: 0.8762 - val_loss: 0.2931 - val_accuracy: 0.8889\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2997 - accuracy: 0.8857 - val_loss: 0.2713 - val_accuracy: 0.8889\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2830 - accuracy: 0.8952 - val_loss: 0.2537 - val_accuracy: 0.9111\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2739 - accuracy: 0.9143 - val_loss: 0.2378 - val_accuracy: 0.9333\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2622 - accuracy: 0.9143 - val_loss: 0.2248 - val_accuracy: 0.9333\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2484 - accuracy: 0.9143 - val_loss: 0.2154 - val_accuracy: 0.9333\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2403 - accuracy: 0.9238 - val_loss: 0.2080 - val_accuracy: 0.9111\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2279 - accuracy: 0.9333 - val_loss: 0.1926 - val_accuracy: 0.9333\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2194 - accuracy: 0.9333 - val_loss: 0.1800 - val_accuracy: 0.9556\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2145 - accuracy: 0.9333 - val_loss: 0.1705 - val_accuracy: 0.9556\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2072 - accuracy: 0.9333 - val_loss: 0.1612 - val_accuracy: 0.9556\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1959 - accuracy: 0.9333 - val_loss: 0.1547 - val_accuracy: 0.9556\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1866 - accuracy: 0.9333 - val_loss: 0.1512 - val_accuracy: 0.9556\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1797 - accuracy: 0.9429 - val_loss: 0.1506 - val_accuracy: 0.9556\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1767 - accuracy: 0.9524 - val_loss: 0.1481 - val_accuracy: 0.9333\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1718 - accuracy: 0.9619 - val_loss: 0.1369 - val_accuracy: 0.9556\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1640 - accuracy: 0.9619 - val_loss: 0.1222 - val_accuracy: 0.9778\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1561 - accuracy: 0.9429 - val_loss: 0.1118 - val_accuracy: 0.9778\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1509 - accuracy: 0.9333 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.9429 - val_loss: 0.1003 - val_accuracy: 0.9778\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1418 - accuracy: 0.9619 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1364 - accuracy: 0.9619 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1302 - accuracy: 0.9619 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1274 - accuracy: 0.9429 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1249 - accuracy: 0.9333 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1201 - accuracy: 0.9429 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1142 - accuracy: 0.9714 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1120 - accuracy: 0.9714 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1084 - accuracy: 0.9714 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1057 - accuracy: 0.9714 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1033 - accuracy: 0.9524 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0994 - accuracy: 0.9714 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0962 - accuracy: 0.9714 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0949 - accuracy: 0.9714 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0908 - accuracy: 0.9810 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0876 - accuracy: 0.9810 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 0.9714 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0854 - accuracy: 0.9714 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0837 - accuracy: 0.9714 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0824 - accuracy: 0.9714 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0799 - accuracy: 0.9810 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0760 - accuracy: 0.9810 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0745 - accuracy: 0.9714 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0724 - accuracy: 0.9810 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0722 - accuracy: 0.9810 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0711 - accuracy: 0.9810 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0749 - accuracy: 0.9714 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0754 - accuracy: 0.9714 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0669 - accuracy: 0.9810 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0662 - accuracy: 0.9810 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0641 - accuracy: 0.9714 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0621 - accuracy: 0.9810 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0614 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0573 - accuracy: 0.9905 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0544 - accuracy: 0.9714 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0508 - accuracy: 0.9905 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0495 - accuracy: 0.9810 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0499 - accuracy: 0.9905 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0489 - accuracy: 0.9905 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0508 - accuracy: 0.9810 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0474 - accuracy: 0.9905 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0476 - accuracy: 0.9905 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0466 - accuracy: 0.9810 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0484 - accuracy: 0.9810 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0489 - accuracy: 0.9810 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 0.9905 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0457 - accuracy: 0.9905 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0461 - accuracy: 0.9810 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0462 - accuracy: 0.9810 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0466 - accuracy: 0.9810 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0448 - accuracy: 0.9810 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0454 - accuracy: 0.9810 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0461 - accuracy: 0.9810 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0476 - accuracy: 0.9810 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0549 - accuracy: 0.9714 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0447 - accuracy: 0.9810 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 0.9714 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0437 - accuracy: 0.9810 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0424 - accuracy: 0.9810 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0433 - accuracy: 0.9905 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0433 - accuracy: 0.9810 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0431 - accuracy: 0.9905 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0436 - accuracy: 0.9810 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0414 - accuracy: 0.9810 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 0.9905 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0436 - accuracy: 0.9810 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0420 - accuracy: 0.9810 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0396 - accuracy: 0.9905 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0451 - accuracy: 0.9810 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0480 - accuracy: 0.9810 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0433 - accuracy: 0.9810 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0396 - accuracy: 0.9905 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0402 - accuracy: 0.9810 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0395 - accuracy: 0.9810 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0378 - accuracy: 0.9905 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0391 - accuracy: 0.9905 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0376 - accuracy: 0.9905 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0373 - accuracy: 0.9905 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0393 - accuracy: 0.9810 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0380 - accuracy: 0.9810 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0365 - accuracy: 0.9905 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 0.9905 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0358 - accuracy: 0.9905 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0360 - accuracy: 0.9905 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 0.9905 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0360 - accuracy: 0.9810 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0376 - accuracy: 0.9810 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9810 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0362 - accuracy: 0.9905 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0350 - accuracy: 0.9905 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0333 - accuracy: 0.9905 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0388 - accuracy: 0.9810 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0376 - accuracy: 0.9810 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9810 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0378 - accuracy: 0.9810 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0328 - accuracy: 0.9905 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9905 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0328 - accuracy: 0.9905 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0354 - accuracy: 0.9810 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0344 - accuracy: 0.9905 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0249 - accuracy: 0.9905 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0244 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9905 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0241 - accuracy: 0.9905 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9905 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0243 - accuracy: 0.9905 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0232 - accuracy: 0.9905 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9905 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0208 - accuracy: 0.9905 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9905 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9905 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9905 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0216 - accuracy: 0.9905 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0239 - accuracy: 0.9905 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0195 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9905 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9905 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0183 - accuracy: 0.9905 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9905 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0188 - accuracy: 0.9905 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0184 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0176 - accuracy: 0.9905 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0174 - accuracy: 0.9905 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 0.9905 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0176 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0179 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0177 - accuracy: 0.9905 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0157 - accuracy: 0.9905 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0165 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0148 - accuracy: 0.9905 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0149 - accuracy: 0.9905 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9905 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9905 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9905 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0132 - accuracy: 0.9905 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0133 - accuracy: 0.9905 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0134 - accuracy: 0.9905 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 9.6855e-04 - val_accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 9.3683e-04 - val_accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 9.0751e-04 - val_accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 9.0409e-04 - val_accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 9.1340e-04 - val_accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 8.9257e-04 - val_accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 9.3157e-04 - val_accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 9.1406e-04 - val_accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 8.9449e-04 - val_accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 9.0646e-04 - val_accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 9.2803e-04 - val_accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 9.1495e-04 - val_accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 8.8196e-04 - val_accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 8.4860e-04 - val_accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 8.4243e-04 - val_accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 8.2801e-04 - val_accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 8.1552e-04 - val_accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 7.9870e-04 - val_accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 8.7155e-04 - val_accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 8.6180e-04 - val_accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 7.9980e-04 - val_accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 8.6183e-04 - val_accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 8.7127e-04 - val_accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 8.8496e-04 - val_accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 8.1127e-04 - val_accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.6520e-04 - val_accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 7.2966e-04 - val_accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 7.0722e-04 - val_accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 6.9504e-04 - val_accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 7.2492e-04 - val_accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.5225e-04 - val_accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.9583e-04 - val_accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 7.4423e-04 - val_accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 6.7771e-04 - val_accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 6.6114e-04 - val_accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 6.7650e-04 - val_accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 7.4349e-04 - val_accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 7.4071e-04 - val_accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 6.8199e-04 - val_accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 7.0451e-04 - val_accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 7.1951e-04 - val_accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 6.9955e-04 - val_accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 6.7618e-04 - val_accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 6.5260e-04 - val_accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 6.2896e-04 - val_accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 6.0911e-04 - val_accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.8508e-04 - val_accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 6.0639e-04 - val_accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.8513e-04 - val_accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.9167e-04 - val_accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.0168e-04 - val_accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.9983e-04 - val_accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.8040e-04 - val_accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.6257e-04 - val_accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.4359e-04 - val_accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.3154e-04 - val_accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.2395e-04 - val_accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.1846e-04 - val_accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.1509e-04 - val_accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.0445e-04 - val_accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.0347e-04 - val_accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.0383e-04 - val_accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.0016e-04 - val_accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.9641e-04 - val_accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.9946e-04 - val_accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.6425e-04 - val_accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.2825e-04 - val_accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.7340e-04 - val_accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.9734e-04 - val_accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.8950e-04 - val_accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6766e-04 - val_accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.3538e-04 - val_accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.3730e-04 - val_accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.5716e-04 - val_accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.8808e-04 - val_accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.0543e-04 - val_accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.2876e-04 - val_accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.0851e-04 - val_accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.2401e-04 - val_accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.3653e-04 - val_accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.3368e-04 - val_accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.2633e-04 - val_accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.2954e-04 - val_accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.2290e-04 - val_accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1681e-04 - val_accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1190e-04 - val_accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.4677e-04 - val_accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.5106e-04 - val_accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.2611e-04 - val_accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.0963e-04 - val_accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.0635e-04 - val_accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.0100e-04 - val_accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.9835e-04 - val_accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.9067e-04 - val_accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.8261e-04 - val_accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.8104e-04 - val_accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.7614e-04 - val_accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.7174e-04 - val_accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.7753e-04 - val_accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.2539e-04 - val_accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.4743e-04 - val_accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.1985e-04 - val_accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9212e-04 - val_accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.8266e-04 - val_accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.8893e-04 - val_accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.8087e-04 - val_accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.2387e-04 - val_accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.6085e-04 - val_accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.2923e-04 - val_accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.8967e-04 - val_accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.8039e-04 - val_accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.7805e-04 - val_accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6837e-04 - val_accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.4970e-04 - val_accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.8453e-04 - val_accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.1954e-04 - val_accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.7657e-04 - val_accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.2522e-04 - val_accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1134e-04 - val_accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0731e-04 - val_accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2186e-04 - val_accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.4663e-04 - val_accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.4575e-04 - val_accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.3386e-04 - val_accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2095e-04 - val_accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1602e-04 - val_accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.2278e-04 - val_accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0882e-04 - val_accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9243e-04 - val_accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8574e-04 - val_accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8413e-04 - val_accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1102e-04 - val_accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0241e-04 - val_accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8372e-04 - val_accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7310e-04 - val_accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6798e-04 - val_accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6683e-04 - val_accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6820e-04 - val_accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7003e-04 - val_accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8622e-04 - val_accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9385e-04 - val_accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8554e-04 - val_accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7756e-04 - val_accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 99ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7659e-04 - val_accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7465e-04 - val_accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6642e-04 - val_accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6379e-04 - val_accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5462e-04 - val_accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5109e-04 - val_accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5217e-04 - val_accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5433e-04 - val_accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5113e-04 - val_accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4930e-04 - val_accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4763e-04 - val_accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5081e-04 - val_accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7355e-04 - val_accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8278e-04 - val_accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.7500e-04 - val_accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6280e-04 - val_accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.5311e-04 - val_accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4505e-04 - val_accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.4109e-04 - val_accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3829e-04 - val_accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3359e-04 - val_accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.3184e-04 - val_accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.3076e-04 - val_accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2977e-04 - val_accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2579e-04 - val_accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2389e-04 - val_accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2172e-04 - val_accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1979e-04 - val_accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1962e-04 - val_accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2117e-04 - val_accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1861e-04 - val_accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1840e-04 - val_accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1595e-04 - val_accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1641e-04 - val_accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.2585e-04 - val_accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3325e-04 - val_accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.2684e-04 - val_accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1961e-04 - val_accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1667e-04 - val_accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1895e-04 - val_accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1782e-04 - val_accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1352e-04 - val_accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0955e-04 - val_accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0525e-04 - val_accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0362e-04 - val_accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0204e-04 - val_accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9875e-04 - val_accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9569e-04 - val_accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9024e-04 - val_accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8918e-04 - val_accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9069e-04 - val_accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8930e-04 - val_accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9030e-04 - val_accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9425e-04 - val_accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1339e-04 - val_accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0684e-04 - val_accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0377e-04 - val_accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1811e-04 - val_accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1722e-04 - val_accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0284e-04 - val_accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8661e-04 - val_accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8338e-04 - val_accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8205e-04 - val_accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8033e-04 - val_accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7789e-04 - val_accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7532e-04 - val_accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7542e-04 - val_accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7552e-04 - val_accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7590e-04 - val_accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7327e-04 - val_accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7438e-04 - val_accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7052e-04 - val_accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6767e-04 - val_accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6829e-04 - val_accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6908e-04 - val_accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6729e-04 - val_accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.9166e-04 - accuracy: 1.0000 - val_loss: 1.6609e-04 - val_accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 9.8844e-04 - accuracy: 1.0000 - val_loss: 1.6716e-04 - val_accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6990e-04 - val_accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 9.7731e-04 - accuracy: 1.0000 - val_loss: 1.6758e-04 - val_accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 9.8399e-04 - accuracy: 1.0000 - val_loss: 1.6846e-04 - val_accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.6407e-04 - accuracy: 1.0000 - val_loss: 1.8266e-04 - val_accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9327e-04 - val_accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0327e-04 - val_accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9632e-04 - val_accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8094e-04 - val_accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 9.3990e-04 - accuracy: 1.0000 - val_loss: 1.7152e-04 - val_accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 9.3712e-04 - accuracy: 1.0000 - val_loss: 1.6491e-04 - val_accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.8307e-04 - accuracy: 1.0000 - val_loss: 1.6392e-04 - val_accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.6735e-04 - accuracy: 1.0000 - val_loss: 1.8743e-04 - val_accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.7884e-04 - accuracy: 1.0000 - val_loss: 2.0180e-04 - val_accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0272e-04 - val_accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.9454e-04 - accuracy: 1.0000 - val_loss: 1.8797e-04 - val_accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.4723e-04 - accuracy: 1.0000 - val_loss: 1.7826e-04 - val_accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.2056e-04 - accuracy: 1.0000 - val_loss: 1.7765e-04 - val_accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.1252e-04 - accuracy: 1.0000 - val_loss: 1.7139e-04 - val_accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 8.9955e-04 - accuracy: 1.0000 - val_loss: 1.6647e-04 - val_accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 8.8132e-04 - accuracy: 1.0000 - val_loss: 1.6292e-04 - val_accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.7585e-04 - accuracy: 1.0000 - val_loss: 1.6029e-04 - val_accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.8259e-04 - accuracy: 1.0000 - val_loss: 1.5803e-04 - val_accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 9.0588e-04 - accuracy: 1.0000 - val_loss: 1.5650e-04 - val_accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.5952e-04 - accuracy: 1.0000 - val_loss: 1.5892e-04 - val_accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.5468e-04 - accuracy: 1.0000 - val_loss: 1.7447e-04 - val_accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.2106e-04 - accuracy: 1.0000 - val_loss: 1.8411e-04 - val_accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.2448e-04 - accuracy: 1.0000 - val_loss: 1.8042e-04 - val_accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 9.0834e-04 - accuracy: 1.0000 - val_loss: 1.6979e-04 - val_accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 8.7633e-04 - accuracy: 1.0000 - val_loss: 1.7249e-04 - val_accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.7106e-04 - accuracy: 1.0000 - val_loss: 1.7020e-04 - val_accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 8.3680e-04 - accuracy: 1.0000 - val_loss: 1.6346e-04 - val_accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.3467e-04 - accuracy: 1.0000 - val_loss: 1.5693e-04 - val_accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.1731e-04 - accuracy: 1.0000 - val_loss: 1.6226e-04 - val_accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.1425e-04 - accuracy: 1.0000 - val_loss: 1.6240e-04 - val_accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.2073e-04 - accuracy: 1.0000 - val_loss: 1.6172e-04 - val_accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 8.1118e-04 - accuracy: 1.0000 - val_loss: 1.5739e-04 - val_accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.0065e-04 - accuracy: 1.0000 - val_loss: 1.5787e-04 - val_accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.8990e-04 - accuracy: 1.0000 - val_loss: 1.5323e-04 - val_accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.7946e-04 - accuracy: 1.0000 - val_loss: 1.4779e-04 - val_accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 8.0221e-04 - accuracy: 1.0000 - val_loss: 1.4377e-04 - val_accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.7712e-04 - accuracy: 1.0000 - val_loss: 1.4420e-04 - val_accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.7479e-04 - accuracy: 1.0000 - val_loss: 1.4774e-04 - val_accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.5328e-04 - accuracy: 1.0000 - val_loss: 1.5945e-04 - val_accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.0526e-04 - accuracy: 1.0000 - val_loss: 1.6444e-04 - val_accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.9725e-04 - accuracy: 1.0000 - val_loss: 1.5693e-04 - val_accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.6536e-04 - accuracy: 1.0000 - val_loss: 1.5176e-04 - val_accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.5557e-04 - accuracy: 1.0000 - val_loss: 1.4783e-04 - val_accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.3064e-04 - accuracy: 1.0000 - val_loss: 1.4104e-04 - val_accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.4828e-04 - accuracy: 1.0000 - val_loss: 1.3923e-04 - val_accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.4705e-04 - accuracy: 1.0000 - val_loss: 1.3521e-04 - val_accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.3864e-04 - accuracy: 1.0000 - val_loss: 1.3323e-04 - val_accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 7.3019e-04 - accuracy: 1.0000 - val_loss: 1.3251e-04 - val_accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.1372e-04 - accuracy: 1.0000 - val_loss: 1.3018e-04 - val_accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.0883e-04 - accuracy: 1.0000 - val_loss: 1.2915e-04 - val_accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.1568e-04 - accuracy: 1.0000 - val_loss: 1.2947e-04 - val_accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 7.0452e-04 - accuracy: 1.0000 - val_loss: 1.2953e-04 - val_accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.9754e-04 - accuracy: 1.0000 - val_loss: 1.2822e-04 - val_accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.9095e-04 - accuracy: 1.0000 - val_loss: 1.2414e-04 - val_accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.9656e-04 - accuracy: 1.0000 - val_loss: 1.2148e-04 - val_accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.0432e-04 - accuracy: 1.0000 - val_loss: 1.2049e-04 - val_accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.9893e-04 - accuracy: 1.0000 - val_loss: 1.1927e-04 - val_accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.2444e-04 - accuracy: 1.0000 - val_loss: 1.1821e-04 - val_accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.2008e-04 - accuracy: 1.0000 - val_loss: 1.1813e-04 - val_accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 7.0898e-04 - accuracy: 1.0000 - val_loss: 1.1756e-04 - val_accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.9032e-04 - accuracy: 1.0000 - val_loss: 1.1795e-04 - val_accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.6980e-04 - accuracy: 1.0000 - val_loss: 1.1915e-04 - val_accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.5885e-04 - accuracy: 1.0000 - val_loss: 1.2107e-04 - val_accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.5346e-04 - accuracy: 1.0000 - val_loss: 1.2347e-04 - val_accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.6556e-04 - accuracy: 1.0000 - val_loss: 1.2572e-04 - val_accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.6799e-04 - accuracy: 1.0000 - val_loss: 1.2613e-04 - val_accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.5802e-04 - accuracy: 1.0000 - val_loss: 1.2143e-04 - val_accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.4227e-04 - accuracy: 1.0000 - val_loss: 1.1943e-04 - val_accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.5582e-04 - accuracy: 1.0000 - val_loss: 1.1801e-04 - val_accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 6.4453e-04 - accuracy: 1.0000 - val_loss: 1.2965e-04 - val_accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.5647e-04 - accuracy: 1.0000 - val_loss: 1.3832e-04 - val_accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 6.5664e-04 - accuracy: 1.0000 - val_loss: 1.3856e-04 - val_accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.4689e-04 - accuracy: 1.0000 - val_loss: 1.3403e-04 - val_accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.5639e-04 - accuracy: 1.0000 - val_loss: 1.2833e-04 - val_accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.2660e-04 - accuracy: 1.0000 - val_loss: 1.3121e-04 - val_accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.2681e-04 - accuracy: 1.0000 - val_loss: 1.2848e-04 - val_accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.2494e-04 - accuracy: 1.0000 - val_loss: 1.2351e-04 - val_accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 6.2731e-04 - accuracy: 1.0000 - val_loss: 1.1673e-04 - val_accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.1571e-04 - accuracy: 1.0000 - val_loss: 1.1388e-04 - val_accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 6.0912e-04 - accuracy: 1.0000 - val_loss: 1.1350e-04 - val_accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.9823e-04 - accuracy: 1.0000 - val_loss: 1.1247e-04 - val_accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.9792e-04 - accuracy: 1.0000 - val_loss: 1.1148e-04 - val_accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.9633e-04 - accuracy: 1.0000 - val_loss: 1.1079e-04 - val_accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.9269e-04 - accuracy: 1.0000 - val_loss: 1.1046e-04 - val_accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.9073e-04 - accuracy: 1.0000 - val_loss: 1.0970e-04 - val_accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.9573e-04 - accuracy: 1.0000 - val_loss: 1.0736e-04 - val_accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.9579e-04 - accuracy: 1.0000 - val_loss: 1.0704e-04 - val_accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.9169e-04 - accuracy: 1.0000 - val_loss: 1.0740e-04 - val_accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.8042e-04 - accuracy: 1.0000 - val_loss: 1.0796e-04 - val_accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.7134e-04 - accuracy: 1.0000 - val_loss: 1.0894e-04 - val_accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.7654e-04 - accuracy: 1.0000 - val_loss: 1.1077e-04 - val_accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 5.6797e-04 - accuracy: 1.0000 - val_loss: 1.1036e-04 - val_accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.6773e-04 - accuracy: 1.0000 - val_loss: 1.0835e-04 - val_accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.6206e-04 - accuracy: 1.0000 - val_loss: 1.0806e-04 - val_accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.5556e-04 - accuracy: 1.0000 - val_loss: 1.0756e-04 - val_accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.5300e-04 - accuracy: 1.0000 - val_loss: 1.0592e-04 - val_accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.4794e-04 - accuracy: 1.0000 - val_loss: 1.0436e-04 - val_accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.4838e-04 - accuracy: 1.0000 - val_loss: 1.0415e-04 - val_accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.4496e-04 - accuracy: 1.0000 - val_loss: 1.0393e-04 - val_accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 5.4420e-04 - accuracy: 1.0000 - val_loss: 1.0374e-04 - val_accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.4146e-04 - accuracy: 1.0000 - val_loss: 1.0546e-04 - val_accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.3474e-04 - accuracy: 1.0000 - val_loss: 1.1507e-04 - val_accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.5274e-04 - accuracy: 1.0000 - val_loss: 1.1988e-04 - val_accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.5611e-04 - accuracy: 1.0000 - val_loss: 1.1961e-04 - val_accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.5424e-04 - accuracy: 1.0000 - val_loss: 1.1617e-04 - val_accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.3755e-04 - accuracy: 1.0000 - val_loss: 1.1103e-04 - val_accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.4695e-04 - accuracy: 1.0000 - val_loss: 1.0481e-04 - val_accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.2625e-04 - accuracy: 1.0000 - val_loss: 1.0273e-04 - val_accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.2750e-04 - accuracy: 1.0000 - val_loss: 1.0098e-04 - val_accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 5.1958e-04 - accuracy: 1.0000 - val_loss: 1.0093e-04 - val_accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.1522e-04 - accuracy: 1.0000 - val_loss: 1.0190e-04 - val_accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.1366e-04 - accuracy: 1.0000 - val_loss: 1.0250e-04 - val_accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.2136e-04 - accuracy: 1.0000 - val_loss: 1.0357e-04 - val_accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.1417e-04 - accuracy: 1.0000 - val_loss: 1.0184e-04 - val_accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 5.0351e-04 - accuracy: 1.0000 - val_loss: 1.0505e-04 - val_accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.1682e-04 - accuracy: 1.0000 - val_loss: 1.0765e-04 - val_accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 5.1276e-04 - accuracy: 1.0000 - val_loss: 1.0592e-04 - val_accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5.0552e-04 - accuracy: 1.0000 - val_loss: 1.0076e-04 - val_accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5.0261e-04 - accuracy: 1.0000 - val_loss: 9.6190e-05 - val_accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.9586e-04 - accuracy: 1.0000 - val_loss: 9.3231e-05 - val_accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.9632e-04 - accuracy: 1.0000 - val_loss: 9.1431e-05 - val_accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.0997e-04 - accuracy: 1.0000 - val_loss: 9.1333e-05 - val_accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.7624e-04 - accuracy: 1.0000 - val_loss: 9.9352e-05 - val_accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.9608e-04 - accuracy: 1.0000 - val_loss: 1.0647e-04 - val_accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.0649e-04 - accuracy: 1.0000 - val_loss: 1.0827e-04 - val_accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.1058e-04 - accuracy: 1.0000 - val_loss: 1.0680e-04 - val_accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.9613e-04 - accuracy: 1.0000 - val_loss: 1.0166e-04 - val_accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.8235e-04 - accuracy: 1.0000 - val_loss: 9.7208e-05 - val_accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.7623e-04 - accuracy: 1.0000 - val_loss: 9.3908e-05 - val_accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.7260e-04 - accuracy: 1.0000 - val_loss: 9.2028e-05 - val_accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.6601e-04 - accuracy: 1.0000 - val_loss: 8.9810e-05 - val_accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.6428e-04 - accuracy: 1.0000 - val_loss: 8.8349e-05 - val_accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.6640e-04 - accuracy: 1.0000 - val_loss: 8.7968e-05 - val_accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.6955e-04 - accuracy: 1.0000 - val_loss: 8.6660e-05 - val_accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.6591e-04 - accuracy: 1.0000 - val_loss: 8.6353e-05 - val_accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.5973e-04 - accuracy: 1.0000 - val_loss: 8.5710e-05 - val_accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.6281e-04 - accuracy: 1.0000 - val_loss: 8.4248e-05 - val_accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.6658e-04 - accuracy: 1.0000 - val_loss: 8.3636e-05 - val_accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.6387e-04 - accuracy: 1.0000 - val_loss: 8.3358e-05 - val_accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.5984e-04 - accuracy: 1.0000 - val_loss: 8.3885e-05 - val_accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.5185e-04 - accuracy: 1.0000 - val_loss: 8.4304e-05 - val_accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.5477e-04 - accuracy: 1.0000 - val_loss: 8.5601e-05 - val_accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.4126e-04 - accuracy: 1.0000 - val_loss: 8.5775e-05 - val_accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.3919e-04 - accuracy: 1.0000 - val_loss: 8.7136e-05 - val_accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.6025e-04 - accuracy: 1.0000 - val_loss: 9.4513e-05 - val_accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.5096e-04 - accuracy: 1.0000 - val_loss: 9.5476e-05 - val_accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.5061e-04 - accuracy: 1.0000 - val_loss: 9.0197e-05 - val_accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.3465e-04 - accuracy: 1.0000 - val_loss: 9.2679e-05 - val_accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.3423e-04 - accuracy: 1.0000 - val_loss: 9.2523e-05 - val_accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.3460e-04 - accuracy: 1.0000 - val_loss: 9.0057e-05 - val_accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.2610e-04 - accuracy: 1.0000 - val_loss: 8.8204e-05 - val_accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.2520e-04 - accuracy: 1.0000 - val_loss: 8.5994e-05 - val_accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.1088e-04 - accuracy: 1.0000 - val_loss: 8.1775e-05 - val_accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.2278e-04 - accuracy: 1.0000 - val_loss: 7.9395e-05 - val_accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.2507e-04 - accuracy: 1.0000 - val_loss: 7.8546e-05 - val_accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.2085e-04 - accuracy: 1.0000 - val_loss: 7.9850e-05 - val_accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.1409e-04 - accuracy: 1.0000 - val_loss: 8.0147e-05 - val_accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.1538e-04 - accuracy: 1.0000 - val_loss: 8.1547e-05 - val_accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.0894e-04 - accuracy: 1.0000 - val_loss: 8.1475e-05 - val_accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.0983e-04 - accuracy: 1.0000 - val_loss: 8.0123e-05 - val_accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.0244e-04 - accuracy: 1.0000 - val_loss: 7.8791e-05 - val_accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.1505e-04 - accuracy: 1.0000 - val_loss: 7.7603e-05 - val_accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.0648e-04 - accuracy: 1.0000 - val_loss: 7.7523e-05 - val_accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.0766e-04 - accuracy: 1.0000 - val_loss: 7.7788e-05 - val_accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.0571e-04 - accuracy: 1.0000 - val_loss: 7.6393e-05 - val_accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.0292e-04 - accuracy: 1.0000 - val_loss: 7.6303e-05 - val_accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.9989e-04 - accuracy: 1.0000 - val_loss: 7.7364e-05 - val_accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.0151e-04 - accuracy: 1.0000 - val_loss: 7.9464e-05 - val_accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.9236e-04 - accuracy: 1.0000 - val_loss: 8.0049e-05 - val_accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.9198e-04 - accuracy: 1.0000 - val_loss: 8.0734e-05 - val_accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8730e-04 - accuracy: 1.0000 - val_loss: 8.0049e-05 - val_accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8468e-04 - accuracy: 1.0000 - val_loss: 7.9408e-05 - val_accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.8335e-04 - accuracy: 1.0000 - val_loss: 7.9151e-05 - val_accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.8428e-04 - accuracy: 1.0000 - val_loss: 7.9971e-05 - val_accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8273e-04 - accuracy: 1.0000 - val_loss: 8.0331e-05 - val_accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.8144e-04 - accuracy: 1.0000 - val_loss: 8.7968e-05 - val_accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.8281e-04 - accuracy: 1.0000 - val_loss: 9.1640e-05 - val_accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.8836e-04 - accuracy: 1.0000 - val_loss: 9.2351e-05 - val_accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8388e-04 - accuracy: 1.0000 - val_loss: 8.9859e-05 - val_accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.7920e-04 - accuracy: 1.0000 - val_loss: 8.7319e-05 - val_accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.7447e-04 - accuracy: 1.0000 - val_loss: 8.4000e-05 - val_accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.6795e-04 - accuracy: 1.0000 - val_loss: 7.7185e-05 - val_accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.6567e-04 - accuracy: 1.0000 - val_loss: 7.4422e-05 - val_accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.7705e-04 - accuracy: 1.0000 - val_loss: 7.2058e-05 - val_accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.7483e-04 - accuracy: 1.0000 - val_loss: 7.2437e-05 - val_accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.7144e-04 - accuracy: 1.0000 - val_loss: 7.3577e-05 - val_accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.6208e-04 - accuracy: 1.0000 - val_loss: 7.3879e-05 - val_accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.6334e-04 - accuracy: 1.0000 - val_loss: 7.5310e-05 - val_accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.5569e-04 - accuracy: 1.0000 - val_loss: 7.5704e-05 - val_accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.5612e-04 - accuracy: 1.0000 - val_loss: 7.6458e-05 - val_accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.5378e-04 - accuracy: 1.0000 - val_loss: 7.5736e-05 - val_accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.5302e-04 - accuracy: 1.0000 - val_loss: 7.5648e-05 - val_accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.4937e-04 - accuracy: 1.0000 - val_loss: 7.4148e-05 - val_accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.4823e-04 - accuracy: 1.0000 - val_loss: 7.2110e-05 - val_accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.4457e-04 - accuracy: 1.0000 - val_loss: 6.9532e-05 - val_accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.4811e-04 - accuracy: 1.0000 - val_loss: 6.8224e-05 - val_accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.4802e-04 - accuracy: 1.0000 - val_loss: 6.7308e-05 - val_accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.4790e-04 - accuracy: 1.0000 - val_loss: 6.6760e-05 - val_accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.4440e-04 - accuracy: 1.0000 - val_loss: 6.7586e-05 - val_accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.4238e-04 - accuracy: 1.0000 - val_loss: 6.8785e-05 - val_accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.3893e-04 - accuracy: 1.0000 - val_loss: 6.8364e-05 - val_accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.4087e-04 - accuracy: 1.0000 - val_loss: 6.7948e-05 - val_accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.3940e-04 - accuracy: 1.0000 - val_loss: 6.8904e-05 - val_accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.4222e-04 - accuracy: 1.0000 - val_loss: 7.6214e-05 - val_accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.5023e-04 - accuracy: 1.0000 - val_loss: 7.9458e-05 - val_accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.4722e-04 - accuracy: 1.0000 - val_loss: 7.7590e-05 - val_accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.3976e-04 - accuracy: 1.0000 - val_loss: 7.5568e-05 - val_accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.3564e-04 - accuracy: 1.0000 - val_loss: 7.3789e-05 - val_accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.2974e-04 - accuracy: 1.0000 - val_loss: 7.1164e-05 - val_accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.2607e-04 - accuracy: 1.0000 - val_loss: 6.8999e-05 - val_accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.2374e-04 - accuracy: 1.0000 - val_loss: 6.7519e-05 - val_accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.2632e-04 - accuracy: 1.0000 - val_loss: 6.6725e-05 - val_accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.2571e-04 - accuracy: 1.0000 - val_loss: 6.5309e-05 - val_accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.2572e-04 - accuracy: 1.0000 - val_loss: 6.4795e-05 - val_accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.2468e-04 - accuracy: 1.0000 - val_loss: 6.4891e-05 - val_accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.2335e-04 - accuracy: 1.0000 - val_loss: 6.5854e-05 - val_accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.1782e-04 - accuracy: 1.0000 - val_loss: 6.6293e-05 - val_accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.1591e-04 - accuracy: 1.0000 - val_loss: 6.6997e-05 - val_accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.1359e-04 - accuracy: 1.0000 - val_loss: 6.8209e-05 - val_accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.1767e-04 - accuracy: 1.0000 - val_loss: 7.0559e-05 - val_accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.1430e-04 - accuracy: 1.0000 - val_loss: 7.0033e-05 - val_accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.1161e-04 - accuracy: 1.0000 - val_loss: 6.8606e-05 - val_accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.0869e-04 - accuracy: 1.0000 - val_loss: 6.7320e-05 - val_accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.0654e-04 - accuracy: 1.0000 - val_loss: 6.5559e-05 - val_accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.0737e-04 - accuracy: 1.0000 - val_loss: 6.3714e-05 - val_accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.0601e-04 - accuracy: 1.0000 - val_loss: 6.2687e-05 - val_accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.0167e-04 - accuracy: 1.0000 - val_loss: 6.3396e-05 - val_accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.0014e-04 - accuracy: 1.0000 - val_loss: 6.4235e-05 - val_accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.0726e-04 - accuracy: 1.0000 - val_loss: 7.0213e-05 - val_accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.0349e-04 - accuracy: 1.0000 - val_loss: 7.1470e-05 - val_accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.0480e-04 - accuracy: 1.0000 - val_loss: 7.1613e-05 - val_accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.0208e-04 - accuracy: 1.0000 - val_loss: 7.0446e-05 - val_accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.0036e-04 - accuracy: 1.0000 - val_loss: 6.9075e-05 - val_accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9980e-04 - accuracy: 1.0000 - val_loss: 6.5081e-05 - val_accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.9636e-04 - accuracy: 1.0000 - val_loss: 6.2263e-05 - val_accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9426e-04 - accuracy: 1.0000 - val_loss: 6.1895e-05 - val_accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.9015e-04 - accuracy: 1.0000 - val_loss: 6.7146e-05 - val_accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.9560e-04 - accuracy: 1.0000 - val_loss: 7.0379e-05 - val_accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9496e-04 - accuracy: 1.0000 - val_loss: 7.0569e-05 - val_accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.9484e-04 - accuracy: 1.0000 - val_loss: 7.0162e-05 - val_accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.9179e-04 - accuracy: 1.0000 - val_loss: 6.8873e-05 - val_accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.9244e-04 - accuracy: 1.0000 - val_loss: 6.4149e-05 - val_accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.8183e-04 - accuracy: 1.0000 - val_loss: 6.4072e-05 - val_accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.8084e-04 - accuracy: 1.0000 - val_loss: 6.3577e-05 - val_accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.7869e-04 - accuracy: 1.0000 - val_loss: 6.2241e-05 - val_accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.8224e-04 - accuracy: 1.0000 - val_loss: 6.1794e-05 - val_accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.7709e-04 - accuracy: 1.0000 - val_loss: 6.6817e-05 - val_accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.8050e-04 - accuracy: 1.0000 - val_loss: 6.9978e-05 - val_accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.8674e-04 - accuracy: 1.0000 - val_loss: 7.0756e-05 - val_accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.8471e-04 - accuracy: 1.0000 - val_loss: 6.6172e-05 - val_accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.7248e-04 - accuracy: 1.0000 - val_loss: 6.3025e-05 - val_accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.6848e-04 - accuracy: 1.0000 - val_loss: 5.9311e-05 - val_accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.6994e-04 - accuracy: 1.0000 - val_loss: 5.7542e-05 - val_accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.6932e-04 - accuracy: 1.0000 - val_loss: 5.6337e-05 - val_accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.6915e-04 - accuracy: 1.0000 - val_loss: 5.5667e-05 - val_accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.6665e-04 - accuracy: 1.0000 - val_loss: 5.5734e-05 - val_accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.6567e-04 - accuracy: 1.0000 - val_loss: 5.6771e-05 - val_accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.6197e-04 - accuracy: 1.0000 - val_loss: 5.7563e-05 - val_accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.6055e-04 - accuracy: 1.0000 - val_loss: 5.7721e-05 - val_accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.6129e-04 - accuracy: 1.0000 - val_loss: 5.7351e-05 - val_accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.6180e-04 - accuracy: 1.0000 - val_loss: 6.0408e-05 - val_accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.5869e-04 - accuracy: 1.0000 - val_loss: 6.1570e-05 - val_accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.6539e-04 - accuracy: 1.0000 - val_loss: 6.2636e-05 - val_accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.5897e-04 - accuracy: 1.0000 - val_loss: 6.0815e-05 - val_accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.5099e-04 - accuracy: 1.0000 - val_loss: 5.7777e-05 - val_accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.5215e-04 - accuracy: 1.0000 - val_loss: 5.5151e-05 - val_accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.5355e-04 - accuracy: 1.0000 - val_loss: 5.3639e-05 - val_accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.5732e-04 - accuracy: 1.0000 - val_loss: 5.1910e-05 - val_accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.5871e-04 - accuracy: 1.0000 - val_loss: 5.1672e-05 - val_accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.5534e-04 - accuracy: 1.0000 - val_loss: 5.1621e-05 - val_accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.5574e-04 - accuracy: 1.0000 - val_loss: 5.1052e-05 - val_accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.5269e-04 - accuracy: 1.0000 - val_loss: 5.1221e-05 - val_accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.4963e-04 - accuracy: 1.0000 - val_loss: 5.1738e-05 - val_accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.4848e-04 - accuracy: 1.0000 - val_loss: 5.2476e-05 - val_accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.4518e-04 - accuracy: 1.0000 - val_loss: 5.2648e-05 - val_accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 2.4427e-04 - accuracy: 1.0000 - val_loss: 5.2442e-05 - val_accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.4310e-04 - accuracy: 1.0000 - val_loss: 5.1727e-05 - val_accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.4205e-04 - accuracy: 1.0000 - val_loss: 5.2436e-05 - val_accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.4009e-04 - accuracy: 1.0000 - val_loss: 5.3061e-05 - val_accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.3876e-04 - accuracy: 1.0000 - val_loss: 5.3029e-05 - val_accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.3979e-04 - accuracy: 1.0000 - val_loss: 5.2473e-05 - val_accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 2.4112e-04 - accuracy: 1.0000 - val_loss: 5.3293e-05 - val_accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.3813e-04 - accuracy: 1.0000 - val_loss: 5.2057e-05 - val_accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.3459e-04 - accuracy: 1.0000 - val_loss: 5.1504e-05 - val_accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.3544e-04 - accuracy: 1.0000 - val_loss: 5.1633e-05 - val_accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.3251e-04 - accuracy: 1.0000 - val_loss: 5.1424e-05 - val_accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.3423e-04 - accuracy: 1.0000 - val_loss: 5.0283e-05 - val_accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.3242e-04 - accuracy: 1.0000 - val_loss: 5.0254e-05 - val_accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.3340e-04 - accuracy: 1.0000 - val_loss: 4.9086e-05 - val_accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.3272e-04 - accuracy: 1.0000 - val_loss: 4.7927e-05 - val_accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.3104e-04 - accuracy: 1.0000 - val_loss: 4.6648e-05 - val_accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.3356e-04 - accuracy: 1.0000 - val_loss: 4.6444e-05 - val_accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.3352e-04 - accuracy: 1.0000 - val_loss: 4.5454e-05 - val_accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.3349e-04 - accuracy: 1.0000 - val_loss: 4.5528e-05 - val_accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.3153e-04 - accuracy: 1.0000 - val_loss: 4.5769e-05 - val_accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.2930e-04 - accuracy: 1.0000 - val_loss: 4.6690e-05 - val_accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.2610e-04 - accuracy: 1.0000 - val_loss: 4.7164e-05 - val_accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.2417e-04 - accuracy: 1.0000 - val_loss: 4.7452e-05 - val_accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.2542e-04 - accuracy: 1.0000 - val_loss: 4.8048e-05 - val_accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.2041e-04 - accuracy: 1.0000 - val_loss: 4.7977e-05 - val_accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.2029e-04 - accuracy: 1.0000 - val_loss: 4.9218e-05 - val_accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.2194e-04 - accuracy: 1.0000 - val_loss: 5.4701e-05 - val_accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.2600e-04 - accuracy: 1.0000 - val_loss: 5.7782e-05 - val_accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.3169e-04 - accuracy: 1.0000 - val_loss: 5.8690e-05 - val_accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.2756e-04 - accuracy: 1.0000 - val_loss: 5.6832e-05 - val_accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.2365e-04 - accuracy: 1.0000 - val_loss: 5.4439e-05 - val_accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.1760e-04 - accuracy: 1.0000 - val_loss: 5.1940e-05 - val_accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.0798e-04 - accuracy: 1.0000 - val_loss: 4.7670e-05 - val_accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.1289e-04 - accuracy: 1.0000 - val_loss: 4.4204e-05 - val_accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.3244e-04 - accuracy: 1.0000 - val_loss: 4.2657e-05 - val_accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.2920e-04 - accuracy: 1.0000 - val_loss: 4.2742e-05 - val_accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.2062e-04 - accuracy: 1.0000 - val_loss: 4.2935e-05 - val_accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.1557e-04 - accuracy: 1.0000 - val_loss: 4.3515e-05 - val_accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.1232e-04 - accuracy: 1.0000 - val_loss: 4.4741e-05 - val_accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.0900e-04 - accuracy: 1.0000 - val_loss: 4.6149e-05 - val_accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.0738e-04 - accuracy: 1.0000 - val_loss: 4.7046e-05 - val_accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.0748e-04 - accuracy: 1.0000 - val_loss: 4.7123e-05 - val_accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.0815e-04 - accuracy: 1.0000 - val_loss: 4.6824e-05 - val_accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.0367e-04 - accuracy: 1.0000 - val_loss: 4.4481e-05 - val_accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.0387e-04 - accuracy: 1.0000 - val_loss: 4.3231e-05 - val_accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 2.0408e-04 - accuracy: 1.0000 - val_loss: 4.2815e-05 - val_accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 2.0527e-04 - accuracy: 1.0000 - val_loss: 4.2763e-05 - val_accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 2.0321e-04 - accuracy: 1.0000 - val_loss: 4.3236e-05 - val_accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.0204e-04 - accuracy: 1.0000 - val_loss: 4.3853e-05 - val_accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.0066e-04 - accuracy: 1.0000 - val_loss: 4.4931e-05 - val_accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.0380e-04 - accuracy: 1.0000 - val_loss: 4.9947e-05 - val_accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0320e-04 - accuracy: 1.0000 - val_loss: 5.2538e-05 - val_accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0381e-04 - accuracy: 1.0000 - val_loss: 5.2184e-05 - val_accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.0218e-04 - accuracy: 1.0000 - val_loss: 5.0855e-05 - val_accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.0234e-04 - accuracy: 1.0000 - val_loss: 4.8573e-05 - val_accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.9657e-04 - accuracy: 1.0000 - val_loss: 4.7406e-05 - val_accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.9417e-04 - accuracy: 1.0000 - val_loss: 4.6241e-05 - val_accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.9340e-04 - accuracy: 1.0000 - val_loss: 4.5458e-05 - val_accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.9293e-04 - accuracy: 1.0000 - val_loss: 4.5193e-05 - val_accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.9230e-04 - accuracy: 1.0000 - val_loss: 4.4724e-05 - val_accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.9131e-04 - accuracy: 1.0000 - val_loss: 4.3832e-05 - val_accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.9150e-04 - accuracy: 1.0000 - val_loss: 4.3183e-05 - val_accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9164e-04 - accuracy: 1.0000 - val_loss: 4.2805e-05 - val_accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9070e-04 - accuracy: 1.0000 - val_loss: 4.2977e-05 - val_accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8896e-04 - accuracy: 1.0000 - val_loss: 4.2712e-05 - val_accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.8756e-04 - accuracy: 1.0000 - val_loss: 4.2892e-05 - val_accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.8746e-04 - accuracy: 1.0000 - val_loss: 4.4345e-05 - val_accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.9008e-04 - accuracy: 1.0000 - val_loss: 5.0073e-05 - val_accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.9547e-04 - accuracy: 1.0000 - val_loss: 5.2347e-05 - val_accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.9710e-04 - accuracy: 1.0000 - val_loss: 5.1582e-05 - val_accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.9376e-04 - accuracy: 1.0000 - val_loss: 4.9449e-05 - val_accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.8767e-04 - accuracy: 1.0000 - val_loss: 4.6720e-05 - val_accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.8710e-04 - accuracy: 1.0000 - val_loss: 4.3503e-05 - val_accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.8319e-04 - accuracy: 1.0000 - val_loss: 4.2227e-05 - val_accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.8599e-04 - accuracy: 1.0000 - val_loss: 4.1184e-05 - val_accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8319e-04 - accuracy: 1.0000 - val_loss: 4.1149e-05 - val_accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.8232e-04 - accuracy: 1.0000 - val_loss: 4.1332e-05 - val_accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.8124e-04 - accuracy: 1.0000 - val_loss: 4.0882e-05 - val_accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.7955e-04 - accuracy: 1.0000 - val_loss: 3.9881e-05 - val_accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.8048e-04 - accuracy: 1.0000 - val_loss: 3.9833e-05 - val_accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.8253e-04 - accuracy: 1.0000 - val_loss: 3.9998e-05 - val_accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.7689e-04 - accuracy: 1.0000 - val_loss: 4.3659e-05 - val_accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.7654e-04 - accuracy: 1.0000 - val_loss: 4.6240e-05 - val_accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.7807e-04 - accuracy: 1.0000 - val_loss: 4.7005e-05 - val_accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.7930e-04 - accuracy: 1.0000 - val_loss: 4.6952e-05 - val_accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.7764e-04 - accuracy: 1.0000 - val_loss: 4.5824e-05 - val_accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.7653e-04 - accuracy: 1.0000 - val_loss: 4.4768e-05 - val_accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.7504e-04 - accuracy: 1.0000 - val_loss: 4.7548e-05 - val_accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.7634e-04 - accuracy: 1.0000 - val_loss: 4.8154e-05 - val_accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.7531e-04 - accuracy: 1.0000 - val_loss: 4.7052e-05 - val_accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.7708e-04 - accuracy: 1.0000 - val_loss: 4.4138e-05 - val_accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.7234e-04 - accuracy: 1.0000 - val_loss: 4.2353e-05 - val_accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.7541e-04 - accuracy: 1.0000 - val_loss: 4.0315e-05 - val_accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.7183e-04 - accuracy: 1.0000 - val_loss: 4.0437e-05 - val_accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.6926e-04 - accuracy: 1.0000 - val_loss: 4.0905e-05 - val_accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.6864e-04 - accuracy: 1.0000 - val_loss: 4.1109e-05 - val_accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.6813e-04 - accuracy: 1.0000 - val_loss: 4.1556e-05 - val_accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.6490e-04 - accuracy: 1.0000 - val_loss: 4.3931e-05 - val_accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.7087e-04 - accuracy: 1.0000 - val_loss: 4.4283e-05 - val_accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.6711e-04 - accuracy: 1.0000 - val_loss: 4.1517e-05 - val_accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.6642e-04 - accuracy: 1.0000 - val_loss: 3.9997e-05 - val_accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.6593e-04 - accuracy: 1.0000 - val_loss: 4.0005e-05 - val_accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.6008e-04 - accuracy: 1.0000 - val_loss: 4.2409e-05 - val_accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.6337e-04 - accuracy: 1.0000 - val_loss: 4.4267e-05 - val_accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.6410e-04 - accuracy: 1.0000 - val_loss: 4.4339e-05 - val_accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.6536e-04 - accuracy: 1.0000 - val_loss: 4.3986e-05 - val_accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.6301e-04 - accuracy: 1.0000 - val_loss: 4.3073e-05 - val_accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.6167e-04 - accuracy: 1.0000 - val_loss: 4.1270e-05 - val_accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.5864e-04 - accuracy: 1.0000 - val_loss: 4.0007e-05 - val_accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5771e-04 - accuracy: 1.0000 - val_loss: 3.8697e-05 - val_accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5970e-04 - accuracy: 1.0000 - val_loss: 3.7622e-05 - val_accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5890e-04 - accuracy: 1.0000 - val_loss: 3.8006e-05 - val_accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5755e-04 - accuracy: 1.0000 - val_loss: 3.7807e-05 - val_accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5656e-04 - accuracy: 1.0000 - val_loss: 3.7873e-05 - val_accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.5764e-04 - accuracy: 1.0000 - val_loss: 3.7860e-05 - val_accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5737e-04 - accuracy: 1.0000 - val_loss: 3.6184e-05 - val_accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.5588e-04 - accuracy: 1.0000 - val_loss: 3.5842e-05 - val_accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.5496e-04 - accuracy: 1.0000 - val_loss: 3.6176e-05 - val_accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5455e-04 - accuracy: 1.0000 - val_loss: 3.6922e-05 - val_accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.5413e-04 - accuracy: 1.0000 - val_loss: 3.7444e-05 - val_accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5352e-04 - accuracy: 1.0000 - val_loss: 3.7232e-05 - val_accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.5373e-04 - accuracy: 1.0000 - val_loss: 3.5985e-05 - val_accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5304e-04 - accuracy: 1.0000 - val_loss: 3.5358e-05 - val_accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5245e-04 - accuracy: 1.0000 - val_loss: 3.5209e-05 - val_accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.5202e-04 - accuracy: 1.0000 - val_loss: 3.4002e-05 - val_accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5577e-04 - accuracy: 1.0000 - val_loss: 3.3417e-05 - val_accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.5507e-04 - accuracy: 1.0000 - val_loss: 3.3983e-05 - val_accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5293e-04 - accuracy: 1.0000 - val_loss: 3.3284e-05 - val_accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5331e-04 - accuracy: 1.0000 - val_loss: 3.3149e-05 - val_accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.5172e-04 - accuracy: 1.0000 - val_loss: 3.3462e-05 - val_accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.5082e-04 - accuracy: 1.0000 - val_loss: 3.3988e-05 - val_accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.4802e-04 - accuracy: 1.0000 - val_loss: 3.4089e-05 - val_accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.4725e-04 - accuracy: 1.0000 - val_loss: 3.4939e-05 - val_accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.4307e-04 - accuracy: 1.0000 - val_loss: 3.8526e-05 - val_accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5127e-04 - accuracy: 1.0000 - val_loss: 4.1711e-05 - val_accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5112e-04 - accuracy: 1.0000 - val_loss: 4.2670e-05 - val_accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.5090e-04 - accuracy: 1.0000 - val_loss: 4.1785e-05 - val_accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.4819e-04 - accuracy: 1.0000 - val_loss: 4.0682e-05 - val_accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.4635e-04 - accuracy: 1.0000 - val_loss: 3.8754e-05 - val_accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.4280e-04 - accuracy: 1.0000 - val_loss: 3.7155e-05 - val_accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.4171e-04 - accuracy: 1.0000 - val_loss: 3.5715e-05 - val_accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.4132e-04 - accuracy: 1.0000 - val_loss: 3.4542e-05 - val_accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.4281e-04 - accuracy: 1.0000 - val_loss: 3.3668e-05 - val_accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.4301e-04 - accuracy: 1.0000 - val_loss: 3.3840e-05 - val_accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.4226e-04 - accuracy: 1.0000 - val_loss: 3.3851e-05 - val_accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.4194e-04 - accuracy: 1.0000 - val_loss: 3.4137e-05 - val_accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.4086e-04 - accuracy: 1.0000 - val_loss: 3.4595e-05 - val_accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.3935e-04 - accuracy: 1.0000 - val_loss: 3.4216e-05 - val_accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.3964e-04 - accuracy: 1.0000 - val_loss: 3.4046e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    epochs=1000, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f5e702",
      "metadata": {
        "id": "01f5e702"
      },
      "source": [
        "Here, we define a sequential neural network model using Keras. We add 3 dense layers with 64, 32, and 16 neurons each, respectively, and use the rectified linear unit (ReLU) activation function. We also add a final dense layer with 3 neurons for output using the softmax activation function. We compile the model using the Adam optimizer and categorical cross-entropy loss function.\n",
        "\n",
        "We then fit the model on the training data for 100 epochs with a batch size of 32. We also evaluate the model on the testing data using the validation_data parameter and accuracy as a metric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5b506c",
      "metadata": {
        "id": "0f5b506c"
      },
      "source": [
        "### Compute and plot the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "806f31e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "806f31e0",
        "outputId": "690754c2-7150-4e29-8300-7eae3cc78ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'True labels')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017132a8",
      "metadata": {
        "id": "017132a8"
      },
      "source": [
        "### Plot the residual, training and testing error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e42a377c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "e42a377c",
        "outputId": "2164be6e-449e-4fd1-e85f-5cdc28a751df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOEUlEQVR4nO3deVxU5f4H8M+ZgZkBZFNgWELAJZdUUFFC2ywKl0jNXUskl2tpalS3bBFtEW/dzLyZlqXeX5maZuYtlwwrs8wddy1X3AAJZRBZZ57fH8jAyCKjZ+bA8Hm/XnOBM8858z3n3prPfZZzJCGEABEREZGDUCldABEREZGcGG6IiIjIoTDcEBERkUNhuCEiIiKHwnBDREREDoXhhoiIiBwKww0RERE5FIYbIiIicigMN0RERORQGG6ISDaSJGH69OlW73f69GlIkoQlS5bIXhMRNTwMN0QOZsmSJZAkCZIkYevWrZXeF0IgODgYkiTh0UcfVaBCeaxbtw6SJCEwMBAmk0npcoioDmG4IXJQOp0OX375ZaXtv/zyC86dOwetVqtAVfJZunQpQkNDcfHiRWzevFnpcoioDmG4IXJQvXv3xsqVK1FSUmKx/csvv0Tnzp3h7++vUGW3Ly8vD99++y0SExPRsWNHLF26VOmSqpWXl6d0CUQNDsMNkYMaNmwY/v77b2zatMm8raioCKtWrcLw4cOr3CcvLw/PP/88goODodVq0apVK/z73/+GEMKiXWFhIZ577jn4+vrC3d0djz32GM6dO1flMc+fP4+nnnoKer0eWq0Wd911FxYtWnRb5/bNN98gPz8fgwYNwtChQ7F69WoUFBRUaldQUIDp06fjzjvvhE6nQ0BAAB5//HGcOHHC3MZkMuGDDz5A+/btodPp4Ovri549e2LXrl0Aap4PdOMco+nTp0OSJBw+fBjDhw+Ht7c37rnnHgDA/v37MWrUKDRr1gw6nQ7+/v546qmn8Pfff1d5zUaPHo3AwEBotVqEhYXh6aefRlFREU6ePAlJkvD+++9X2u/333+HJElYtmyZtZeUyKE4KV0AEdlGaGgooqOjsWzZMvTq1QsAsH79euTk5GDo0KGYO3euRXshBB577DH89NNPGD16NCIiIrBx40a8+OKLOH/+vMWX6ZgxY/DFF19g+PDh6NatGzZv3ow+ffpUqiEjIwN33303JEnCxIkT4evri/Xr12P06NEwGAyYMmXKLZ3b0qVL0aNHD/j7+2Po0KF4+eWX8b///Q+DBg0ytzEajXj00UeRkpKCoUOHYvLkycjNzcWmTZtw8OBBNG/eHAAwevRoLFmyBL169cKYMWNQUlKCX3/9FX/88QciIyNvqb5BgwahZcuWmDlzpjkYbtq0CSdPnkRCQgL8/f1x6NAhfPLJJzh06BD++OMPSJIEALhw4QK6du2KK1euYNy4cWjdujXOnz+PVatW4dq1a2jWrBm6d++OpUuX4rnnnqt0Xdzd3dG3b99bqpvIYQgiciiLFy8WAMTOnTvFhx9+KNzd3cW1a9eEEEIMGjRI9OjRQwghREhIiOjTp495vzVr1ggA4q233rI43sCBA4UkSeL48eNCCCFSU1MFAPHMM89YtBs+fLgAIJKSkszbRo8eLQICAkRWVpZF26FDhwpPT09zXadOnRIAxOLFi296fhkZGcLJyUksXLjQvK1bt26ib9++Fu0WLVokAIjZs2dXOobJZBJCCLF582YBQEyaNKnaNjXVduP5JiUlCQBi2LBhldqWnWtFy5YtEwDEli1bzNtGjhwpVCqV2LlzZ7U1ffzxxwKAOHLkiPm9oqIi4ePjI+Lj4yvtR9TQcFiKyIENHjwY+fn5+O6775Cbm4vvvvuu2iGpdevWQa1WY9KkSRbbn3/+eQghsH79enM7AJXa3dgLI4TA119/jbi4OAghkJWVZX7FxsYiJycHe/bssfqcli9fDpVKhQEDBpi3DRs2DOvXr8fly5fN277++mv4+Pjg2WefrXSMsl6Sr7/+GpIkISkpqdo2t2L8+PGVtrm4uJh/LygoQFZWFu6++24AMF8Hk8mENWvWIC4urspeo7KaBg8eDJ1OZzHXaOPGjcjKysITTzxxy3UTOQqGGyIH5uvri5iYGHz55ZdYvXo1jEYjBg4cWGXbM2fOIDAwEO7u7hbb27RpY36/7KdKpTIP65Rp1aqVxd+XLl3ClStX8Mknn8DX19filZCQAADIzMy0+py++OILdO3aFX///TeOHz+O48ePo2PHjigqKsLKlSvN7U6cOIFWrVrByan60fcTJ04gMDAQjRs3trqOmoSFhVXalp2djcmTJ0Ov18PFxQW+vr7mdjk5OQBKr5nBYEC7du1qPL6Xlxfi4uIsVsMtXboUQUFBePDBB2U8E6L6iXNuiBzc8OHDMXbsWKSnp6NXr17w8vKyy+eW3XvmiSeeQHx8fJVtOnToYNUx//rrL+zcuRMA0LJly0rvL126FOPGjbOy0ppV14NjNBqr3adiL02ZwYMH4/fff8eLL76IiIgINGrUCCaTCT179ryl+/SMHDkSK1euxO+//4727dtj7dq1eOaZZ6BS8f+zEjHcEDm4/v374x//+Af++OMPrFixotp2ISEh+PHHH5Gbm2vRe3P06FHz+2U/TSaTuWekzLFjxyyOV7aSymg0IiYmRpZzWbp0KZydnfH5559DrVZbvLd161bMnTsXaWlpaNq0KZo3b47t27ejuLgYzs7OVR6vefPm2LhxI7Kzs6vtvfH29gYAXLlyxWJ7WU9WbVy+fBkpKSmYMWMGpk2bZt7+119/WbTz9fWFh4cHDh48eNNj9uzZE76+vli6dCmioqJw7do1PPnkk7WuiciRMeITObhGjRph/vz5mD59OuLi4qpt17t3bxiNRnz44YcW299//31IkmRecVX288bVVnPmzLH4W61WY8CAAfj666+r/LK+dOmS1eeydOlS3HvvvRgyZAgGDhxo8XrxxRcBwLwMesCAAcjKyqp0PgDMK5gGDBgAIQRmzJhRbRsPDw/4+Phgy5YtFu9/9NFHta67LIiJG5bU33jNVCoV+vXrh//973/mpehV1QQATk5OGDZsGL766issWbIE7du3t7onjMhRseeGqAGoblioori4OPTo0QOvvvoqTp8+jfDwcPzwww/49ttvMWXKFPMcm4iICAwbNgwfffQRcnJy0K1bN6SkpOD48eOVjjlr1iz89NNPiIqKwtixY9G2bVtkZ2djz549+PHHH5GdnV3rc9i+fTuOHz+OiRMnVvl+UFAQOnXqhKVLl+Kll17CyJEj8X//939ITEzEjh07cO+99yIvLw8//vgjnnnmGfTt2xc9evTAk08+iblz5+Kvv/4yDxH9+uuv6NGjh/mzxowZg1mzZmHMmDGIjIzEli1b8Oeff9a6dg8PD9x333145513UFxcjKCgIPzwww84depUpbYzZ87EDz/8gPvvvx/jxo1DmzZtcPHiRaxcuRJbt261GFYcOXIk5s6di59++gn/+te/al0PkcNTbqEWEdlCxaXgNblxKbgQQuTm5ornnntOBAYGCmdnZ9GyZUvx7rvvmpcgl8nPzxeTJk0STZo0EW5ubiIuLk6cPXu20tJoIUqXbk+YMEEEBwcLZ2dn4e/vLx566CHxySefmNvUZin4s88+KwCIEydOVNtm+vTpAoDYt2+fEKJ0+fWrr74qwsLCzJ89cOBAi2OUlJSId999V7Ru3VpoNBrh6+srevXqJXbv3m1uc+3aNTF69Gjh6ekp3N3dxeDBg0VmZma1S8EvXbpUqbZz586J/v37Cy8vL+Hp6SkGDRokLly4UOU1O3PmjBg5cqTw9fUVWq1WNGvWTEyYMEEUFhZWOu5dd90lVCqVOHfuXLXXhaihkYS4oZ+UiIjqjY4dO6Jx48ZISUlRuhSiOoNzboiI6qldu3YhNTUVI0eOVLoUojqFPTdERPXMwYMHsXv3brz33nvIysrCyZMnodPplC6LqM5gzw0RUT2zatUqJCQkoLi4GMuWLWOwIboBe26IiIjIobDnhoiIiBwKww0RERE5lAZ3Ez+TyYQLFy7A3d39tp76S0RERPYjhEBubi4CAwNv+gy1BhduLly4gODgYKXLICIioltw9uxZ3HHHHTW2aXDhpuyBgGfPnoWHh4fC1RAREVFtGAwGBAcHWzzYtzoNLtyUDUV5eHgw3BAREdUztZlSwgnFRERE5FAYboiIiMihMNwQERGRQ2G4ISIiIofCcENEREQOheGGiIiIHArDDRERETkUhhsiIiJyKAw3RERE5FAYboiIiMihKBputmzZgri4OAQGBkKSJKxZs+am+/z888/o1KkTtFotWrRogSVLlti8TiIiIqo/FA03eXl5CA8Px7x582rV/tSpU+jTpw969OiB1NRUTJkyBWPGjMHGjRttXCkRERHVF4o+OLNXr17o1atXrdsvWLAAYWFheO+99wAAbdq0wdatW/H+++8jNjbWVmXaX3E+kHdJ6SocQkGJCUXFJni4OMGQXwKNswo6p/JMX2I0IbegBN5uGsv9ik3QOZe2M5oEMnML4NNIiyv5xXDVOKHEaMK1ohL4NtKi0ChgyC8CADRx08JQUIxio8l8LA8Xjfl9IqKGwFnrAh//pop9fr16Kvi2bdsQExNjsS02NhZTpkypdp/CwkIUFhaa/zYYDLYqTx6FucDcjgw3MtFdfwFAVc+AdwLgXc1+ZdQAAq7/7lthu2eFY7hV2O5TxfHcqthGROSojjq1gc9rfyj2+fUq3KSnp0Ov11ts0+v1MBgMyM/Ph4uLS6V9kpOTMWPGDHuVePv+PlEebJx0NbelGpmEQFGJqdJ2jZMKKkmCAFBYbAQAqFQSNOrSnpqC69sAQOusNrchIqLaMaqUjRf1KtzciqlTpyIxMdH8t8FgQHBwsIIV3UTxtdKfjZsDk/YoW0s9t+VYJkYt3llp+6JhkXiwtR4nMq8iZvYvAIAerXyxOKErAKD1y9+b2/46uQfufeenm35Wv4hA7DiVjQs5BQCAZWPvRnTzJgi9fqxGWiccnOFAQ6dERDW4S+HPr1fhxt/fHxkZGRbbMjIy4OHhUWWvDQBotVpotVp7lCePouvhRuOqbB0OIDO3sOrthsLr7xeYt2UYqmlboU1N/Dx08PPQmcONn4fl/+akWh2FiIjkUK/CTXR0NNatW2exbdOmTYiOjlaoIhsoziv96SzfLI2tf2Uh9exlTOjRApJU/jX7v30XkJNfjPA7vLBsZxrua+mL7af+Rmt/d2RdLUJeYQmmxNwJjZPlorq1+y7gky0n0K25Dwz5xdA4qeCqcUKnpl7YdeYyCoqNuFZkhIuzGmqVhKuFJeZ93TRqdGvhg5+OZqLEJHDkogHx3UKRkVOAM9nXqqz/yEUD2gRUNWOmZn9m5Fa5fen2NOw6cxnnLpd/3qmsPLywcl+ltrM3/Vmrz/Jz18JdV/6Pk96DQ4pEREpRNNxcvXoVx48fN/996tQppKamonHjxmjatCmmTp2K8+fP4//+7/8AAOPHj8eHH36If/7zn3jqqaewefNmfPXVV/j++++r+4j6xwY9N098th0A0MKvEXq2K50aW2I04dllewEA7jon5BaU4MvtaZX27XCHF3q28zf/XWw0YdL1/Q6ev7XJ2f/ddsbi73+u2n/TfQ5dkG8i+IHzOThwPsdiW36xEat2n6vU9rfjf1d7nG7Nm+D3E6Xvh/m44fyVfPz6VxZcnNVopC39R6traGPsOJ2NQZF1eCiUiMjBKBpudu3ahR49epj/LpsbEx8fjyVLluDixYtISyv/wg0LC8P333+P5557Dh988AHuuOMOfPrppw62DLys50aecCOEMP9+4lKe+fe/88qXJucWlKA6F67kW/yddbXq4Zua6D20GNUtDLvPZOPHI5nVtgtt4oohXSyXDv5rw1Hz7y/1bG31ZzfSquGiccKl3EL4NNKgoMSEqxXOV+Okgk8jDS5csRx+MhQUw0PnDABwVku4t6Uvtp3IQqcQbxxLz4WnizM6hXjj29QL8HRxxgOt/NA5xBshjV3RKaR8/dWCJzvjp6OZ6N0+AEREZB+KhpsHHnjA4sv3RlXdffiBBx7A3r17bViVwoqvhwmNPMNSOfnFVW7PMNRuLknGDXNOqpubcqM7vF1w7nLpubTy98DTDzTHt6m6GsNNhzu88PQDzS22ffTzcXP4uvE9e2vl7w6gtM4yo+8JM//u5arBqO5hFvs0dtNgQOc77FIfERGVqldzbhqEsmGpanpucvKLoXVSQeesxrWiEpgEYDQK5BYWw99Dh7/ziuCqUUMlSbh8rQins8rnlZy/ko9zl6/B08UZR9Orno9yozNZ13Du8jW4aZxQbDLhRObVWu3XPsjTHG707qWTa/3ca56HoveoPPGbE3GJiMhaDDd1TQ3DUrvPXMaQj7fB202Dr/4Rjbj/bLWYrHszX25Pq3JeTU02HErHhkPpVu0DAO2CPLH+YOl+ZSuHKoYXD50TdM5qixVNVU3C9WmkhaGGYTMiIqIb8angdcnhb4HfPij9vYoJxbtOZ6PEJHAptxDf7D1fq2CjrbDS6cZVTze2cXFWAwBcNWqULarSOqmgVlXff3L/nb4I9LQMJU0bu+LxTkG4705f+LprEdOm9MaLIU3ccHezxtA5qzCwczDmP9HJvE+Apw733+mLG70/JALBjV0wb3inSu8RERFVhT03dcmaZ8p/d/ev9HbF+S4Hb1jtU51jb5U/u8toEmj+SulS+vA7PPHtxHtqdYxPtpzAzHXlE3uHRzXFzP7tb7rf/z3V1eJvtUrC8nGWy/ZPz+pT4zHCg73w6z8frFWdREREAHtu6g5jMVB0fT7LQ0lA+PBKTSpO7r1xKXNtVOyBqX4ad2U3zpVRS5wJQ0REdRd7buqKovJl2oieADhpcTmvCB/+dBxXrhXjz4xci0BzqZq779qCtprhLCIiorqI4aauKHumlKQG1BoAwDd7z+OzradqtXvnEG/sPnPZYluX0MrPuw5p4oozf1+z6r4rLfWNLP7u1rxJrfclIiKyN4abusJ8Z2I3lM3mNRRUvkfNuwM7oLDEhNyCEni5OkNC6f1VuoR6Y+2+C4gMaYyDF3KQnVeEoV0q3xV3xbhobDuZhUc7BNa6tBZ+7lg0KhL5RSYYhbC4YzEREVFdw3BTV1SxBLyg2GTRpGlj1xpv459w/QZy7e/wrLaNv6cO/Ttaf1O5B1vrrd6HiIhICQw3dcX1nhuTsyuKio3IzitCQbFR4aKIiIjqH4abOuJIWjraAPjzshGD3voRuVbcnI+IiIjKcRlMHXHqQukzl66atAw2REREt4E9N0q7egkoyYfTlRMAgGui8vOVyvD2MkRERDfHcKOkPZ8DaycCAB65vikf1YcbIiIiujkOSynp7Pbrv5R3yVyrIdwIa24rTERE1EAx3Cip7MZ9d/Y0b8qvYViqT4fa33iPiIiooeKwlJKuL/8Wbj7mvpuqem7eGdgBzmoJvdox3BAREd0Mw42Srt+4L1/TGGW37qsq3Nzh5YJuLXzsWBgREVH9xWEpJV3vuclRld9ROF/oKjXTOqvtVhIREVF9x3CjpOtzbrJFhXADTaVmfCo3ERFR7fFbU0lFpcNSmSZ38yYTKt/MxtPF2W4lERER1XcMN0q63nNzsditxmZ+Hrz3DRERUW0x3Cjp+pybi/mV53U30pZv0zpxzg0REVFtMdwo4dSvwJoJ5tVSv5zOq9SEvTVERES3huFGCRteBlK/MP954kr5rYcPmUIBACOiQgAAfu4MOURERNbgfW6UkH/Z4s9nYztgk/QtYvS5eF4TDY1ahYhgLzRx06BrWGOFiiQiIqqfGG6UUGQ5DDW+x50A7gQAdKuwvV/HIPvVRERE5CA4LKWEsmdKERERkewYbuzNWAIYi5SugoiIyGEx3NhbceWVUURERCQfhht7K+KQFBERkS0x3Ngb59sQERHZFMONvRVxWIqIiMiWGG7sjT03RERENsVwY2/suSEiIrIphht7u95zYxISij1CgKFfKlwQERGRY1E83MybNw+hoaHQ6XSIiorCjh07qm1bXFyMN954A82bN4dOp0N4eDg2bNhgx2pvn7jec/Ob6S5cHrsDaN1H4YqIiIgci6LhZsWKFUhMTERSUhL27NmD8PBwxMbGIjMzs8r2r732Gj7++GP85z//weHDhzF+/Hj0798fe/futXPlt64o/yoAIB9aNNLy6RdERERyUzTczJ49G2PHjkVCQgLatm2LBQsWwNXVFYsWLaqy/eeff45XXnkFvXv3RrNmzfD000+jd+/eeO+99+xc+a2rGG5cnNUKV0NEROR4FAs3RUVF2L17N2JiYsqLUakQExODbdu2VblPYWEhdDqdxTYXFxds3bq12s8pLCyEwWCweCmppKA03BSrXCBJkqK1EBEROSLFwk1WVhaMRiP0er3Fdr1ej/T09Cr3iY2NxezZs/HXX3/BZDJh06ZNWL16NS5evFjt5yQnJ8PT09P8Cg4OlvU8rGUON2oXResgIiJyVIpPKLbGBx98gJYtW6J169bQaDSYOHEiEhISoFJVfxpTp05FTk6O+XX27Fk7VlyZsaB0QrHRieGGiIjIFhQLNz4+PlCr1cjIyLDYnpGRAX9//yr38fX1xZo1a5CXl4czZ87g6NGjaNSoEZo1a1bt52i1Wnh4eFi8lGQsLA03JidXResgIiJyVIqFG41Gg86dOyMlJcW8zWQyISUlBdHR0TXuq9PpEBQUhJKSEnz99dfo27evrcuVTdmwlLOukcKVEBEROSZF1yInJiYiPj4ekZGR6Nq1K+bMmYO8vDwkJCQAAEaOHImgoCAkJycDALZv347z588jIiIC58+fx/Tp02EymfDPf/5TydOoPSEQkr4RAKB1dVe4GCIiIsekaLgZMmQILl26hGnTpiE9PR0RERHYsGGDeZJxWlqaxXyagoICvPbaazh58iQaNWqE3r174/PPP4eXl5dCZ2ClzCPmX1UeAQoWQkRE5LgkIYRQugh7MhgM8PT0RE5Ojv3n35z+DVjSGwCwolcqhkSF2ffziYiI6ilrvr/r1Wqpeu/6c6UOmkLh5+mmcDFERESOieHGnq4/V+oatPB11ypcDBERkWNiuLGjsmXg+UILvYfuJq2JiIjoVvDJjTa283Q2vtl7Ho20Tgj88zBGAciXdGjiplG6NCIiIofEcGNjU5an4vyVfADAOPXfgDNgVLtApeJzpYiIiGyBw1I2VhZsAMBVKgQAFEockiIiIrIVhhs7ckFpuMkHJxMTERHZCoelbKyJczF0xVdwBY3QUjoPgOGGiIjIlhhubMlwAVtU/4CbrsBis6TlPW6IiIhshcNStpRxCG6SZbAphAb39xysUEFERESOjz03NmQszIP6hm3aqSfRQsuHZhIREdkKe25sqKQgt/JGlbP9CyEiImpAGG5sqKQgr/JGNcMNERGRLTHc2JCx8GrljaobB6qIiIhITgw3NmSsqueGiIiIbIrhxoZMRdeULoGIiKjBYbixIVMRe26IiIjsjeHGhv48m6F0CURERA0O73NjC4fXAn9uQItr+5SuhIiIqMFhuLGFbycAhQbola6DiIioAeKwlNxMRqDQAAD40DgALxaPg1HnrXBRREREDQfDjdwqTCL+T3EcVhofgMpJo2BBREREDQvDjdyKS5d/C0gohDO8XZ0hKVwSERFRQ8JwI7frPTdGJ1cAEvzcdcrWQ0RE1MAw3Mjtes9Nibo01Ph5aJWshoiIqMFhuJHb9bsSF0il4UbvwZ4bIiIie2K4kVtR6cMyL14rvbR69twQERHZFcON3K4PS+WjNNQ81IZ3uyEiIrInhhu5XR+Wuia0uMPbBZ2aegNCKFwUERFRw8FwI7fi0tVS+dCVz7fRuClYEBERUcPCcCM3kxEAUAR1+XybQUsA77DSn0RERGRTfLaU3CoMQfk0uh5uAiOAyamKlENERNTQsOdGduL6f0pw1zE7EhER2RvDjdzMPTcS3LQMN0RERPbGcCM7Yf7PRgw3REREdsdwIzdRPizlqmG4ISIisjfFw828efMQGhoKnU6HqKgo7Nixo8b2c+bMQatWreDi4oLg4GA899xzKCgosFO1tScgoZFWrXQZREREDY6i4WbFihVITExEUlIS9uzZg/DwcMTGxiIzM7PK9l9++SVefvllJCUl4ciRI/jss8+wYsUKvPLKK3auvCblq6U454aIiMj+FA03s2fPxtixY5GQkIC2bdtiwYIFcHV1xaJFi6ps//vvv6N79+4YPnw4QkND8cgjj2DYsGE37e2xK1E+54bhhoiIyP4UCzdFRUXYvXs3YmJiyotRqRATE4Nt27ZVuU+3bt2we/duc5g5efIk1q1bh969e1f7OYWFhTAYDBYv2yqfc8MJxURERPan2LdvVlYWjEYj9HrLB0vq9XocPXq0yn2GDx+OrKws3HPPPRBCoKSkBOPHj69xWCo5ORkzZsyQtfYaVZhQ7OLMOTdERET2pviEYmv8/PPPmDlzJj766CPs2bMHq1evxvfff48333yz2n2mTp2KnJwc8+vs2bM2rrJ8WMpJLdn4s4iIiOhGivXc+Pj4QK1WIyMjw2J7RkYG/P39q9zn9ddfx5NPPokxY8YAANq3b4+8vDyMGzcOr776KlSqyllNq9VCq9XKfwLVqXATP5XEcENERGRvivXcaDQadO7cGSkpKeZtJpMJKSkpiI6OrnKfa9euVQowanXp0I+o8EynukBAArMNERGR/Sk64zUxMRHx8fGIjIxE165dMWfOHOTl5SEhIQEAMHLkSAQFBSE5ORkAEBcXh9mzZ6Njx46IiorC8ePH8frrryMuLs4ccpRXHrLYc0NERGR/ioabIUOG4NKlS5g2bRrS09MRERGBDRs2mCcZp6WlWfTUvPbaa5AkCa+99hrOnz8PX19fxMXF4e2331bqFCoxmQRUKB2dYrghIiKyP0nUtfEcGzMYDPD09EROTg48PDxkP77xl39D/dOb+Krkfjzyyip4uWpk/wwiIqKGxprv73q1Wqo+EBWWgkvsuSEiIrI7hhuZiQp3KFarGG6IiIjsjeHGRgQkMNsQERHZH8ONzIQwlf4EJxQTEREpgeFGZhXnZzPbEBER2R/DjcyEiXcoJiIiUhLDjcwqrpZiuCEiIrI/hhuZWc65UbYWIiKihojhRmbC/JP3uSEiIlICw43cyiYUM9gQEREpguFGZmVzbhhtiIiIlMFwIzPBnhsiIiJFMdzIzHR9QjH7boiIiJTBcCM39twQEREpiuFGZuV3KGa4ISIiUgLDjczMN/Fjzw0REZEiGG7kVjYqxZ4bIiIiRTDcyEygdEIxO26IiIiUwXAjM865ISIiUhbDjczMTwVn1w0REZEiGG5kJsCeGyIiIiUx3MjNnG0YboiIiJTAcCMzwTsUExERKYrhRm68QzEREZGiGG5kVjbnhtmGiIhIGQw3MuNScCIiImUx3MjMPOeGXTdERESKYLiRW1nHDXtuiIiIFMFwIzPBCcVERESKYriR3fUJxey5ISIiUgTDjczYc0NERKQshhu5mVdLERERkRIYbmRWtlpKYs8NERGRIhhuZFZ+mxteWiIiIiXwG1h2HJYiIiJSEsONzMonFPPSEhERKaFOfAPPmzcPoaGh0Ol0iIqKwo4dO6pt+8ADD0CSpEqvPn362LHiGgg+W4qIiEhJioebFStWIDExEUlJSdizZw/Cw8MRGxuLzMzMKtuvXr0aFy9eNL8OHjwItVqNQYMG2bnyqvHZUkRERMqyOtyEhobijTfeQFpamiwFzJ49G2PHjkVCQgLatm2LBQsWwNXVFYsWLaqyfePGjeHv729+bdq0Ca6urnUm3IBPBSciIlKU1eFmypQpWL16NZo1a4aHH34Yy5cvR2Fh4S19eFFREXbv3o2YmJjyglQqxMTEYNu2bbU6xmeffYahQ4fCzc3tlmqQmzAPSyneKUZERNQg3VK4SU1NxY4dO9CmTRs8++yzCAgIwMSJE7Fnzx6rjpWVlQWj0Qi9Xm+xXa/XIz09/ab779ixAwcPHsSYMWOqbVNYWAiDwWDxsi3eoZiIiEhJt9y90KlTJ8ydOxcXLlxAUlISPv30U3Tp0gURERFYtGhRhbkntvPZZ5+hffv26Nq1a7VtkpOT4enpaX4FBwfbtCbBp4ITEREp6pbDTXFxMb766is89thjeP755xEZGYlPP/0UAwYMwCuvvIIRI0bc9Bg+Pj5Qq9XIyMiw2J6RkQF/f/8a983Ly8Py5csxevToGttNnToVOTk55tfZs2dvfnK34/oditlzQ0REpAwna3fYs2cPFi9ejGXLlkGlUmHkyJF4//330bp1a3Ob/v37o0uXLjc9lkajQefOnZGSkoJ+/foBAEwmE1JSUjBx4sQa9125ciUKCwvxxBNP1NhOq9VCq9Xe/MTkIvhUcCIiIiVZHW66dOmChx9+GPPnz0e/fv3g7OxcqU1YWBiGDh1aq+MlJiYiPj4ekZGR6Nq1K+bMmYO8vDwkJCQAAEaOHImgoCAkJydb7PfZZ5+hX79+aNKkibWnYFOC97khIiJSlNXh5uTJkwgJCamxjZubGxYvXlyr4w0ZMgSXLl3CtGnTkJ6ejoiICGzYsME8yTgtLQ0qleXo2bFjx7B161b88MMP1pZvB5xQTEREpCSrw01mZibS09MRFRVlsX379u1Qq9WIjIy0uoiJEydWOwz1888/V9rWqlUru0xYvhWcUExERKQsqycUT5gwocpJuefPn8eECRNkKap+KxuWYrghIiJSgtXh5vDhw+jUqVOl7R07dsThw4dlKapeExyWIiIiUpLV4Uar1VZaug0AFy9ehJOT1aNcDqhsXIp3KCYiIlKC1d/AjzzyiPneMWWuXLmCV155BQ8//LCsxdVLdXQuEBERUUNhdVfLv//9b9x3330ICQlBx44dAQCpqanQ6/X4/PPPZS+w/ikbllK2CiIioobK6nATFBSE/fv3Y+nSpdi3bx9cXFyQkJCAYcOGVXnPmwZHcFiKiIhISbc0ScbNzQ3jxo2TuxaHwEEpIiIiZd3yDODDhw8jLS0NRUVFFtsfe+yx2y6qPpN4Ez8iIiJF3dIdivv3748DBw5AkqQKjxso/TI3Go3yVljfmIelGG6IiIiUYPXEkMmTJyMsLAyZmZlwdXXFoUOHsGXLFkRGRlZ5N+GGhz03RERESrK652bbtm3YvHkzfHx8oFKpoFKpcM899yA5ORmTJk3C3r17bVFn/cFJN0RERIqyuufGaDTC3d0dAODj44MLFy4AAEJCQnDs2DF5q6uX2HNDRESkJKt7btq1a4d9+/YhLCwMUVFReOedd6DRaPDJJ5+gWbNmtqixnmK4ISIiUoLV4ea1115DXl4eAOCNN97Ao48+invvvRdNmjTBihUrZC+w3uGzpYiIiBRldbiJjY01/96iRQscPXoU2dnZ8Pb25pOwAZRPuuG1ICIiUoJVc26Ki4vh5OSEgwcPWmxv3Lgxg40Ze26IiIiUZFW4cXZ2RtOmTXkvm5rwPjdERESKsnq11KuvvopXXnkF2dnZtqin3iu7QzE7boiIiJRh9ZybDz/8EMePH0dgYCBCQkLg5uZm8f6ePXtkK65eut5zI9hzQ0REpAirw02/fv1sUIbjMN/Dj103REREirA63CQlJdmiDsdR9qwt9twQEREpwuo5N3QzXC1FRESkJKt7blQqVY3Lvhv6SiqJ97khIiJSlNXh5ptvvrH4u7i4GHv37sV///tfzJgxQ7bC6i1mGyIiIkVZHW769u1badvAgQNx1113YcWKFRg9erQshdVfTDdERERKkm3Ozd13342UlBS5DlePld3nhuGGiIhICbKEm/z8fMydOxdBQUFyHK5+E2U/GG6IiIiUYPWw1I0PyBRCIDc3F66urvjiiy9kLa5+4mopIiIiJVkdbt5//32LcKNSqeDr64uoqCh4e3vLWlz9xDk3RERESrI63IwaNcoGZTgOSXDODRERkZKsnnOzePFirFy5stL2lStX4r///a8sRdVv4uZNiIiIyGasDjfJycnw8fGptN3Pzw8zZ86UpSiHwJ4bIiIiRVgdbtLS0hAWFlZpe0hICNLS0mQpqn7jnBsiIiIlWR1u/Pz8sH///krb9+3bhyZNmshSVL3GOTdERESKsjrcDBs2DJMmTcJPP/0Eo9EIo9GIzZs3Y/LkyRg6dKgtaqyXBMMNERGRIqxeLfXmm2/i9OnTeOihh+DkVLq7yWTCyJEjOecG5aulOCxFRESkDKvDjUajwYoVK/DWW28hNTUVLi4uaN++PUJCQmxRXz3EYSkiIiIl3fLjF1q2bIlBgwbh0Ucfva1gM2/ePISGhkKn0yEqKgo7duyosf2VK1cwYcIEBAQEQKvV4s4778S6detu+fPlx6XgRERESrI63AwYMAD/+te/Km1/5513MGjQIKuOtWLFCiQmJiIpKQl79uxBeHg4YmNjkZmZWWX7oqIiPPzwwzh9+jRWrVqFY8eOYeHChXXzmVbsuSEiIlKE1eFmy5Yt6N27d6XtvXr1wpYtW6w61uzZszF27FgkJCSgbdu2WLBgAVxdXbFo0aIq2y9atAjZ2dlYs2YNunfvjtDQUNx///0IDw+39jRsp2y1FOfcEBERKcLqcHP16lVoNJpK252dnWEwGGp9nKKiIuzevRsxMTHlxahUiImJwbZt26rcZ+3atYiOjsaECROg1+vRrl07zJw5E0ajsdrPKSwshMFgsHjZksQHZxIRESnK6nDTvn17rFixotL25cuXo23btrU+TlZWFoxGI/R6vcV2vV6P9PT0Kvc5efIkVq1aBaPRiHXr1uH111/He++9h7feeqvaz0lOToanp6f5FRwcXOsabw/DDRERkRKsXi31+uuv4/HHH8eJEyfw4IMPAgBSUlLw5ZdfYtWqVbIXWJHJZIKfnx8++eQTqNVqdO7cGefPn8e7776LpKSkKveZOnUqEhMTzX8bDAYbBxz23BARESnJ6nATFxeHNWvWYObMmVi1ahVcXFwQHh6OzZs3o3HjxrU+jo+PD9RqNTIyMiy2Z2RkwN/fv8p9AgIC4OzsDLVabd7Wpk0bpKeno6ioqMrhMq1WC61WW+u6bpvgaikiIiIl3dJS8D59+uC3335DXl4eTp48icGDB+OFF16wamKvRqNB586dkZKSYt5mMpmQkpKC6OjoKvfp3r07jh8/DpPJZN72559/IiAgoMpgoyTe54aIiEgZt3yfmy1btiA+Ph6BgYF477338OCDD+KPP/6w6hiJiYlYuHAh/vvf/+LIkSN4+umnkZeXh4SEBADAyJEjMXXqVHP7p59+GtnZ2Zg8eTL+/PNPfP/995g5cyYmTJhwq6chO4kPziQiIlKUVcNS6enpWLJkCT777DMYDAYMHjwYhYWFWLNmjVWTicsMGTIEly5dwrRp05Ceno6IiAhs2LDBPMk4LS0NKlV5/goODsbGjRvx3HPPoUOHDggKCsLkyZPx0ksvWf3ZtsM7FBMRESlJEqJ2k0Ti4uKwZcsW9OnTByNGjEDPnj2hVqvh7OyMffv23VK4UYLBYICnpydycnLg4eEh+/HT/nU3muYfwXd3zcajg0bLfnwiIqKGyJrv71r33Kxfvx6TJk3C008/jZYtW952kY7K3F/DnhsiIiJF1HrOzdatW5Gbm4vOnTsjKioKH374IbKysmxZWz3FOTdERERKqnW4ufvuu7Fw4UJcvHgR//jHP7B8+XIEBgbCZDJh06ZNyM3NtWWd9Qdvc0NERKQoq1dLubm54amnnsLWrVtx4MABPP/885g1axb8/Pzw2GOP2aLGeqas5+aWF6IRERHRbbitb+BWrVrhnXfewblz57Bs2TK5aqrn2HVDRESkJFm6F9RqNfr164e1a9fKcbh6rew+N4w2REREyuDYidwEe26IiIiUxHAjs/JIw0tLRESkBH4Dy453KCYiIlISww0RERE5FIYbuXHODRERkaIYbmQmcSk4ERGRohhuZMc5N0REREpiuJGZxGdLERERKYrhxlbYc0NERKQIhhsbYbYhIiJSBsON3ASHpYiIiJTEcCMzrpYiIiJSFsON7NhzQ0REpCSGG5lJXApORESkKIYbuZk7bnhpiYiIlMBvYBthzw0REZEyGG5kJ27ehIiIiGyG4UZm5XNuFC6EiIiogWK4kV1Zzw0vLRERkRL4DSwzyTyhmF03RERESmC4kR3vc0NERKQkhhuZmefcqBhuiIiIlMBwIzvOuSEiIlISv4FlpuIdiomIiBTFcCM3wXBDRESkJIYbmfGp4ERERMpiuLEVhhsiIiJFMNzIrPwOxby0RERESuA3sOx4nxsiIiIlMdzIjM+WIiIiUladCDfz5s1DaGgodDodoqKisGPHjmrbLlmyBJIkWbx0Op0dq62ZOdNwWIqIiEgRin8Dr1ixAomJiUhKSsKePXsQHh6O2NhYZGZmVruPh4cHLl68aH6dOXPGjhXfBJeCExERKUrxcDN79myMHTsWCQkJaNu2LRYsWABXV1csWrSo2n0kSYK/v7/5pdfr7VhxzVQwmX8jIiIi+1P0G7ioqAi7d+9GTEyMeZtKpUJMTAy2bdtW7X5Xr15FSEgIgoOD0bdvXxw6dKjatoWFhTAYDBYve+CoFBERkTIU/QrOysqC0Wis1POi1+uRnp5e5T6tWrXCokWL8O233+KLL76AyWRCt27dcO7cuSrbJycnw9PT0/wKDg6W/TwqKptQLNhzQ0REpIh69w0cHR2NkSNHIiIiAvfffz9Wr14NX19ffPzxx1W2nzp1KnJycsyvs2fP2rhCzrkhIiJSkpOSH+7j4wO1Wo2MjAyL7RkZGfD396/VMZydndGxY0ccP368yve1Wi20Wu1t11pbfPwCERGRshTtudFoNOjcuTNSUlLM20wmE1JSUhAdHV2rYxiNRhw4cAABAQG2KtMqZZGGdygmIiJShqI9NwCQmJiI+Ph4REZGomvXrpgzZw7y8vKQkJAAABg5ciSCgoKQnJwMAHjjjTdw9913o0WLFrhy5QreffddnDlzBmPGjFHyNMqVLQVXuAwiIqKGSvFwM2TIEFy6dAnTpk1Deno6IiIisGHDBvMk47S0NKhU5b0gly9fxtixY5Geng5vb2907twZv//+O9q2bavUKVjgsBQREZGyJCGEuHkzx2EwGODp6YmcnBx4eHjIfvzC6X7QohC/P7oZ3SI7y358IiKihsia729ODJFdWc+NWtkyiIiIGiiGG5mZ71DMYSkiIiJFMNzYCLMNERGRMhhuZFY+oZiXloiISAn8BpZZWbiRuBiciIhIEQw3tqJiuCEiIlICw43MyntueGmJiIiUwG9gman44EwiIiJFMdzYCLMNERGRMhhu5FThZs+C6YaIiEgRDDdyEibzrxLvUExERKQIhhs5VXxMF3tuiIiIFMFwI6vycMP73BARESmD4UZOFXpuJBUvLRERkRL4DSyrCuGGHTdERESKYLiRU8WeG6YbIiIiRTDcyKrihGJeWiIiIiXwG1hO7LkhIiJSHMONrMrDjYo9N0RERIrgN7CcuFqKiIhIcfwGllOFOxSrOCxFRESkCIYbWVUYlmLPDRERkSL4DSwnwXBDRESkNH4Dy6o83KhVHJYiIiJSAsONnDihmIiISHH8BrYRNZeCExERKYLfwHLinBsiIiLF8RtYVhXDDefcEBERKYHhRk7suSEiIlIcv4FlVRpuTELiaikiIiKFMNzI6fodigV4h2IiIiKlMNzISJjDjQR23BARESmD4UZGJlPpsJQAh6WIiIiUwnAjI6OpfFhK4rAUERGRIhhuZGSqMCzFnhsiIiJlMNzISJjKloJzzg0REZFS6kS4mTdvHkJDQ6HT6RAVFYUdO3bUar/ly5dDkiT069fPtgXWUsVhKa6WIiIiUobi4WbFihVITExEUlIS9uzZg/DwcMTGxiIzM7PG/U6fPo0XXngB9957r50qvTmT4IRiIiIipSkebmbPno2xY8ciISEBbdu2xYIFC+Dq6opFixZVu4/RaMSIESMwY8YMNGvWzI7V1kwYS3tuTJDYc0NERKQQRcNNUVERdu/ejZiYGPM2lUqFmJgYbNu2rdr93njjDfj5+WH06NE3/YzCwkIYDAaLl62YhBEA73NDRESkJEXDTVZWFoxGI/R6vcV2vV6P9PT0KvfZunUrPvvsMyxcuLBWn5GcnAxPT0/zKzg4+Lbrrk7F+9xwKTgREZEyFB+WskZubi6efPJJLFy4ED4+PrXaZ+rUqcjJyTG/zp49a7P6TCZx80ZERERkU05KfriPjw/UajUyMjIstmdkZMDf379S+xMnTuD06dOIi4szbzNdX6Hk5OSEY8eOoXnz5hb7aLVaaLVaG1RfWcX73BAREZEyFO250Wg06Ny5M1JSUszbTCYTUlJSEB0dXal969atceDAAaSmpppfjz32GHr06IHU1FSbDjnVhsnEcENERKQ0RXtuACAxMRHx8fGIjIxE165dMWfOHOTl5SEhIQEAMHLkSAQFBSE5ORk6nQ7t2rWz2N/LywsAKm1XguCwFBERkeIUDzdDhgzBpUuXMG3aNKSnpyMiIgIbNmwwTzJOS0uDSlU/pgZVvM8NERERKUMSQjSo7gaDwQBPT0/k5OTAw8ND1mOnHduDpst64DLc4T39nKzHJiIiasis+f6uH10i9YS4PueGiIiIlMNwIyOjKLtDMS8rERGRUvgtLCNhLH8qOBERESmD4UZGQpQ/FZyIiIiUwXAjo7Kb+LHnhoiISDkMNzLiTfyIiIiUx3AjI/ODM/nQTCIiIsUw3Miogd0yiIiIqE5iuJERh6WIiIiUp/jjFxxJec8Nww0RUUNkNBpRXFysdBn1lkajkeWRSww3MjKZGG6IiBoiIQTS09Nx5coVpUup11QqFcLCwqDRaG7rOAw3MhLCCAAwcUIxEVGDUhZs/Pz84OrqConfA1YzmUy4cOECLl68iKZNm97WNWS4kZGJw1JERA2O0Wg0B5smTZooXU695uvriwsXLqCkpATOzs63fBxOKJZR+YMzGW6IiBqKsjk2rq6uCldS/5UNRxmNxts6DsONTApLjMg05APgfW6IiBoiDkXdPrmuIcONTA5dMGDR1lPX/+L/wImIqOEJDQ3FnDlzlC6D4UYuEgCNujTUuGo5lYmIiOouSZJqfE2fPv2Wjrtz506MGzdO3mJvAb+FZdKxqTe+HBMFLAG8XG5vCRsREZEtXbx40fz7ihUrMG3aNBw7dsy8rVGjRubfhRAwGo1wcrp5ZPD19ZW30FvEnhtZXV8txXFXIiKqw/z9/c0vT09PSJJk/vvo0aNwd3fH+vXr0blzZ2i1WmzduhUnTpxA3759odfr0ahRI3Tp0gU//vijxXFvHJaSJAmffvop+vfvD1dXV7Rs2RJr1661+fkx3MiJS8GJiBo8IQSuFZUo8pLzGYcvv/wyZs2ahSNHjqBDhw64evUqevfujZSUFOzduxc9e/ZEXFwc0tLSajzOjBkzMHjwYOzfvx+9e/fGiBEjkJ2dLVudVeGwlKzKem6YGYmIGqr8YiPaTtuoyGcffiMWrhp5vtrfeOMNPPzww+a/GzdujPDwcPPfb775Jr755husXbsWEydOrPY4o0aNwrBhwwAAM2fOxNy5c7Fjxw707NlTljqrwm9hOYnr97nhsBQREdVzkZGRFn9fvXoVL7zwAtq0aQMvLy80atQIR44cuWnPTYcOHcy/u7m5wcPDA5mZmTapuQx7buTEYSkiogbPxVmNw2/EKvbZcnFzc7P4+4UXXsCmTZvw73//Gy1atICLiwsGDhyIoqKiGo9z452GJUmCyXzTW9tguJEVJxQTETV0kiTJNjRUl/z2228YNWoU+vfvD6C0J+f06dPKFlUNDkvJiT03RETkoFq2bInVq1cjNTUV+/btw/Dhw23eA3OrGG5kVdZzo2wVREREcps9eza8vb3RrVs3xMXFITY2Fp06dVK6rCpJQs51Y/WAwWCAp6cncnJy4OHhIe/B//oRWDoA8O8AjP9V3mMTEVGdVFBQgFOnTiEsLAw6nU7pcuq1mq6lNd/f7LmRFefcEBERKY3hRk6cc0NERKQ4hhtZseeGiIhIaQw3cjLfxI+XlYiISCn8FpYTh6WIiIgUx3AjKw5LERERKY3hRk7suSEiIlIcw42s2HNDRESkNIYbOZmMpT85oZiIiEgxdeJbeN68eQgNDYVOp0NUVBR27NhRbdvVq1cjMjISXl5ecHNzQ0REBD7//HM7VluD4vzSn86uytZBRETUgCkeblasWIHExEQkJSVhz549CA8PR2xsLDIzM6ts37hxY7z66qvYtm0b9u/fj4SEBCQkJGDjxo12rrwKxXmlP51dlK2DiIioBpIk1fiaPn36bR17zZo1stV6KxQPN7Nnz8bYsWORkJCAtm3bYsGCBXB1dcWiRYuqbP/AAw+gf//+aNOmDZo3b47JkyejQ4cO2Lp1q50rr0LRtdKfGjdl6yAiIqrBxYsXza85c+bAw8PDYtsLL7ygdIm3RdFwU1RUhN27dyMmJsa8TaVSISYmBtu2bbvp/kIIpKSk4NixY7jvvvtsWWrtFF8PNxyWIiKiOszf39/88vT0hCRJFtuWL1+ONm3aQKfToXXr1vjoo4/M+xYVFWHixIkICAiATqdDSEgIkpOTAQChoaEAgP79+0OSJPPf9uakyKdel5WVBaPRCL1eb7Fdr9fj6NGj1e6Xk5ODoKAgFBYWQq1W46OPPsLDDz9cZdvCwkIUFhaa/zYYDPIUX5Wi68NS7LkhImq4hCj/P7v25ux62yt2ly5dimnTpuHDDz9Ex44dsXfvXowdOxZubm6Ij4/H3LlzsXbtWnz11Vdo2rQpzp49i7NnzwIAdu7cCT8/PyxevBg9e/aEWq2W46yspmi4uVXu7u5ITU3F1atXkZKSgsTERDRr1gwPPPBApbbJycmYMWOGfQpjzw0RERVfA2YGKvPZr1y47f+DnZSUhPfeew+PP/44ACAsLAyHDx/Gxx9/jPj4eKSlpaFly5a45557IEkSQkJCzPv6+voCALy8vODv739bddwORcONj48P1Go1MjIyLLZnZGTUeFFUKhVatGgBAIiIiMCRI0eQnJxcZbiZOnUqEhMTzX8bDAYEBwfLcwI3Ms+5YbghIqL6Jy8vDydOnMDo0aMxduxY8/aSkhJ4enoCAEaNGoWHH34YrVq1Qs+ePfHoo4/ikUceUarkKikabjQaDTp37oyUlBT069cPAGAymZCSkoKJEyfW+jgmk8li6KkirVYLrVYrR7k3Z14txWEpIqIGy9m1tAdFqc++DVevXgUALFy4EFFRURbvlQ0xderUCadOncL69evx448/YvDgwYiJicGqVatu67PlpPiwVGJiIuLj4xEZGYmuXbtizpw5yMvLQ0JCAgBg5MiRCAoKMk9WSk5ORmRkJJo3b47CwkKsW7cOn3/+OebPn6/kaQAlhcClY6W/s+eGiKjhkqR6O/dSr9cjMDAQJ0+exIgRI6pt5+HhgSFDhmDIkCEYOHAgevbsiezsbDRu3BjOzs4wGo12rLoyxcPNkCFDcOnSJUybNg3p6emIiIjAhg0bzJOM09LSoFKVL+rKy8vDM888g3PnzsHFxQWtW7fGF198gSFDhih1CqUu7gcuXZ8EzTk3RERUT82YMQOTJk2Cp6cnevbsicLCQuzatQuXL19GYmIiZs+ejYCAAHTs2BEqlQorV66Ev78/vLy8AJSumEpJSUH37t2h1Wrh7e1t93NQPNwAwMSJE6sdhvr5558t/n7rrbfw1ltv2aEqK0kS4KQD3AOAptFKV0NERHRLxowZA1dXV7z77rt48cUX4ebmhvbt22PKlCkAShf1vPPOO/jrr7+gVqvRpUsXrFu3ztwR8d577yExMRELFy5EUFAQTp8+bfdzkIQwP8q6QTAYDPD09EROTg48PDyULoeIiOq5goICnDp1CmFhYdDpdEqXU6/VdC2t+f5W/A7FRERERHJiuCEiIiKHwnBDREREDoXhhoiIiBwKww0RERE5FIYbIiIiGTSwxcc2Idc1ZLghIiK6Dc7OzgCAa9cUehK4AykqKgKA236aeJ24iR8REVF9pVar4eXlhczMTACAq6srJElSuKr6x2Qy4dKlS3B1dYWT0+3FE4YbIiKi2+Tv7w8A5oBDt0alUqFp06a3HQ4ZboiIiG6TJEkICAiAn58fiouLlS6n3tJoNBbPk7xVDDdEREQyUavVtz1fhG4fJxQTERGRQ2G4ISIiIofCcENEREQOpcHNuSm7QZDBYFC4EiIiIqqtsu/t2tzor8GFm9zcXABAcHCwwpUQERGRtXJzc+Hp6VljG0k0sPtFm0wmXLhwAe7u7rLfZMlgMCA4OBhnz56Fh4eHrMemcrzO9sHrbD+81vbB62wftrrOQgjk5uYiMDDwpsvFG1zPjUqlwh133GHTz/Dw8OA/OHbA62wfvM72w2ttH7zO9mGL63yzHpsynFBMREREDoXhhoiIiBwKw42MtFotkpKSoNVqlS7FofE62wevs/3wWtsHr7N91IXr3OAmFBMREZFjY88NERERORSGGyIiInIoDDdERETkUBhuiIiIyKEw3Mhk3rx5CA0NhU6nQ1RUFHbs2KF0SfVKcnIyunTpAnd3d/j5+aFfv344duyYRZuCggJMmDABTZo0QaNGjTBgwABkZGRYtElLS0OfPn3g6uoKPz8/vPjiiygpKbHnqdQrs2bNgiRJmDJlinkbr7M8zp8/jyeeeAJNmjSBi4sL2rdvj127dpnfF0Jg2rRpCAgIgIuLC2JiYvDXX39ZHCM7OxsjRoyAh4cHvLy8MHr0aFy9etXep1KnGY1GvP766wgLC4OLiwuaN2+ON9980+L5Q7zW1tuyZQvi4uIQGBgISZKwZs0ai/fluqb79+/HvffeC51Oh+DgYLzzzjvynICg27Z8+XKh0WjEokWLxKFDh8TYsWOFl5eXyMjIULq0eiM2NlYsXrxYHDx4UKSmporevXuLpk2biqtXr5rbjB8/XgQHB4uUlBSxa9cucffdd4tu3bqZ3y8pKRHt2rUTMTExYu/evWLdunXCx8dHTJ06VYlTqvN27NghQkNDRYcOHcTkyZPN23mdb192drYICQkRo0aNEtu3bxcnT54UGzduFMePHze3mTVrlvD09BRr1qwR+/btE4899pgICwsT+fn55jY9e/YU4eHh4o8//hC//vqraNGihRg2bJgSp1Rnvf3226JJkybiu+++E6dOnRIrV64UjRo1Eh988IG5Da+19datWydeffVVsXr1agFAfPPNNxbvy3FNc3JyhF6vFyNGjBAHDx4Uy5YtEy4uLuLjjz++7foZbmTQtWtXMWHCBPPfRqNRBAYGiuTkZAWrqt8yMzMFAPHLL78IIYS4cuWKcHZ2FitXrjS3OXLkiAAgtm3bJoQo/YdRpVKJ9PR0c5v58+cLDw8PUVhYaN8TqONyc3NFy5YtxaZNm8T9999vDje8zvJ46aWXxD333FPt+yaTSfj7+4t3333XvO3KlStCq9WKZcuWCSGEOHz4sAAgdu7caW6zfv16IUmSOH/+vO2Kr2f69OkjnnrqKYttjz/+uBgxYoQQgtdaDjeGG7mu6UcffSS8vb0t/r3x0ksviVatWt12zRyWuk1FRUXYvXs3YmJizNtUKhViYmKwbds2BSur33JycgAAjRs3BgDs3r0bxcXFFte5devWaNq0qfk6b9u2De3bt4derze3iY2NhcFgwKFDh+xYfd03YcIE9OnTx+J6ArzOclm7di0iIyMxaNAg+Pn5oWPHjli4cKH5/VOnTiE9Pd3iOnt6eiIqKsriOnt5eSEyMtLcJiYmBiqVCtu3b7ffydRx3bp1Q0pKCv78808AwL59+7B161b06tULAK+1Lch1Tbdt24b77rsPGo3G3CY2NhbHjh3D5cuXb6vGBvfgTLllZWXBaDRa/IseAPR6PY4ePapQVfWbyWTClClT0L17d7Rr1w4AkJ6eDo1GAy8vL4u2er0e6enp5jZV/fdQ9h6VWr58Ofbs2YOdO3dWeo/XWR4nT57E/PnzkZiYiFdeeQU7d+7EpEmToNFoEB8fb75OVV3HitfZz8/P4n0nJyc0btyY17mCl19+GQaDAa1bt4ZarYbRaMTbb7+NESNGAACvtQ3IdU3T09MRFhZW6Rhl73l7e99yjQw3VOdMmDABBw8exNatW5UuxeGcPXsWkydPxqZNm6DT6ZQux2GZTCZERkZi5syZAICOHTvi4MGDWLBgAeLj4xWuzrF89dVXWLp0Kb788kvcddddSE1NxZQpUxAYGMhr3YBxWOo2+fj4QK1WV1pNkpGRAX9/f4Wqqr8mTpyI7777Dj/99BPuuOMO83Z/f38UFRXhypUrFu0rXmd/f/8q/3soe49Kh50yMzPRqVMnODk5wcnJCb/88gvmzp0LJycn6PV6XmcZBAQEoG3bthbb2rRpg7S0NADl16mmf2/4+/sjMzPT4v2SkhJkZ2fzOlfw4osv4uWXX8bQoUPRvn17PPnkk3juueeQnJwMgNfaFuS6prb8dwnDzW3SaDTo3LkzUlJSzNtMJhNSUlIQHR2tYGX1ixACEydOxDfffIPNmzdX6qrs3LkznJ2dLa7zsWPHkJaWZr7O0dHROHDggMU/UJs2bYKHh0elL5qG6qGHHsKBAweQmppqfkVGRmLEiBHm33mdb1/37t0r3crgzz//REhICAAgLCwM/v7+FtfZYDBg+/btFtf5ypUr2L17t7nN5s2bYTKZEBUVZYezqB+uXbsGlcryq0ytVsNkMgHgtbYFua5pdHQ0tmzZguLiYnObTZs2oVWrVrc1JAWAS8HlsHz5cqHVasWSJUvE4cOHxbhx44SXl5fFahKq2dNPPy08PT3Fzz//LC5evGh+Xbt2zdxm/PjxomnTpmLz5s1i165dIjo6WkRHR5vfL1ui/Mgjj4jU1FSxYcMG4evryyXKN1FxtZQQvM5y2LFjh3BychJvv/22+Ouvv8TSpUuFq6ur+OKLL8xtZs2aJby8vMS3334r9u/fL/r27VvlUtqOHTuK7du3i61bt4qWLVs26OXJVYmPjxdBQUHmpeCrV68WPj4+4p///Ke5Da+19XJzc8XevXvF3r17BQAxe/ZssXfvXnHmzBkhhDzX9MqVK0Kv14snn3xSHDx4UCxfvly4urpyKXhd8p///Ec0bdpUaDQa0bVrV/HHH38oXVK9AqDK1+LFi81t8vPzxTPPPCO8vb2Fq6ur6N+/v7h48aLFcU6fPi169eolXFxchI+Pj3j++edFcXGxnc+mfrkx3PA6y+N///ufaNeundBqtaJ169bik08+sXjfZDKJ119/Xej1eqHVasVDDz0kjh07ZtHm77//FsOGDRONGjUSHh4eIiEhQeTm5trzNOo8g8EgJk+eLJo2bSp0Op1o1qyZePXVVy2WF/NaW++nn36q8t/J8fHxQgj5rum+ffvEPffcI7RarQgKChKzZs2SpX5JiAq3cSQiIiKq5zjnhoiIiBwKww0RERE5FIYbIiIicigMN0RERORQGG6IiIjIoTDcEBERkUNhuCEiIiKHwnBDRA2eJElYs2aN0mUQkUwYbohIUaNGjYIkSZVePXv2VLo0IqqnnJQugIioZ8+eWLx4scU2rVarUDVEVN+x54aIFKfVauHv72/xKnsqsCRJmD9/Pnr16gUXFxc0a9YMq1atstj/wIEDePDBB+Hi4oImTZpg3LhxuHr1qkWbRYsW4a677oJWq0VAQAAmTpxo8X5WVhb69+8PV1dXtGzZEmvXrrXtSRORzTDcEFGd9/rrr2PAgAHYt28fRowYgaFDh+LIkSMAgLy8PMTGxsLb2xs7d+7EypUr8eOPP1qEl/nz52PChAkYN24cDhw4gLVr16JFixYWnzFjxgwMHjwY+/fvR+/evTFixAhkZ2fb9TyJSCayPH6TiOgWxcfHC7VaLdzc3Cxeb7/9thCi9Inx48ePt9gnKipKPP3000IIIT755BPh7e0trl69an7/+++/FyqVSqSnpwshhAgMDBSvvvpqtTUAEK+99pr576tXrwoAYv369bKdJxHZD+fcEJHievTogfnz51tsa9y4sfn36Ohoi/eio6ORmpoKADhy5AjCw8Ph5uZmfr979+4wmUw4duwYJEnChQsX8NBDD9VYQ4cOHcy/u7m5wcPDA5mZmbd6SkSkIIYbIlKcm5tbpWEiubi4uNSqnbOzs8XfkiTBZDLZoiQisjHOuSGiOu+PP/6o9HebNm0AAG3atMG+ffuQl5dnfv+3336DSqVCq1at4O7ujtDQUKSkpNi1ZiJSDntuiEhxhYWFSE9Pt9jm5OQEHx8fAMDKlSsRGRmJe+65B0uXLsWOHTvw2WefAQBGjBiBpKQkxMfHY/r06bh06RKeffZZPPnkk9Dr9QCA6dOnY/z48fDz80OvXr2Qm5uL3377Dc8++6x9T5SI7ILhhogUt2HDBgQEBFhsa9WqFY4ePQqgdCXT8uXL8cwzzyAgIADLli1D27ZtAQCurq7YuHEjJk+ejC5dusDV1RUDBgzA7NmzzceKj49HQUEB3n//fbzwwgvw8fHBwIED7XeCRGRXkhBCKF0EEVF1JEnCN998g379+ildChHVE5xzQ0RERA6F4YaIiIgcCufcEFGdxpFzIrIWe26IiIjIoTDcEBERkUNhuCEiIiKHwnBDREREDoXhhoiIiBwKww0RERE5FIYbIiIicigMN0RERORQGG6IiIjIofw/Nfy0GeG1Gq0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ac587fc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ac587fc9",
        "outputId": "9449a7ce-65bc-4ccc-bb58-38061c41dbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss:  0.00013823156768921763\n",
            "Training Accuracy:  1.0\n",
            "Testing Loss:  3.404644667170942e-05\n",
            "Testing Accuracy:  1.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the training and testing data\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Training Loss: \", train_loss)\n",
        "print(\"Training Accuracy: \", train_accuracy)\n",
        "print(\"Testing Loss: \", test_loss)\n",
        "print(\"Testing Accuracy: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Based on the observed loss and accuracy metrics, it is evident that the model achieves a remarkably high accuracy as it progresses towards 100 epochs and beyond. By the end of the 1000th epoch, the model achieves 100% accuracy when making predictions on the test data. It is worth noting that the accuracy metrics do not significantly differ from the results obtained from the previous model.\n",
        "\n",
        "However, when comparing the training and testing loss, the model employing the sigmoid activation function yields slightly higher values than the model using the Tanh activation function. Additionally, while the sigmoid model consists of 3 hidden layers, the Tanh model only comprises 2 hidden layers.\n",
        "\n",
        "From these observations, we can conclude that the Tanh activation function performs better than the sigmoid activation function for multi-class classification problems."
      ],
      "metadata": {
        "id": "x2N0Rfe5bw9b"
      },
      "id": "x2N0Rfe5bw9b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}